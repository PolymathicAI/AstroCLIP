{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset('../../astroclip/datasets/legacy_survey.py', \n",
    "                       cache_dir='/mnt/ceph/users/sgolkar/datasets')\n",
    "\n",
    "# Drop the image and redshift features\n",
    "dataset = dataset.remove_columns([\"image\", \"redshift\"])\n",
    "\n",
    "# Split the test set 50/50 into test and val\n",
    "test_half_length = len(dataset['test']) // 2\n",
    "test_data = dataset['test'].select(indices=range(test_half_length))\n",
    "val_data = dataset['test'].select(indices=range(test_half_length, len(dataset['test'])))\n",
    "\n",
    "# modify the dataset dict to reflect the split\n",
    "dataset['test'] = test_data\n",
    "dataset['val'] = val_data\n",
    "\n",
    "dataset = dataset.rename_column('spectrum', 'x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c984bd050d1430d8b3d4019e3200109",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/20 shards):   0%|          | 0/158380 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38224dc2ff334936b20c2e1a6c2f2157",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/3 shards):   0%|          | 0/19798 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47034836647d41999144e98cd87db20b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/3 shards):   0%|          | 0/19798 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "path = \"/mnt/ceph/users/sgolkar/datasets/astroclip/spectrum_ds\"\n",
    "dataset.save_to_disk(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f0cea5e1bc14bb881c471809a150fab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=30):   0%|          | 0/158380 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "972da87b79564fceb17173fc1bf9e9dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=30):   0%|          | 0/19798 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2830341a08142d4a9b6f6fa887be588",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=30):   0%|          | 0/19798 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "def fnc(samples):\n",
    "    out = []\n",
    "    for sample in samples[\"x\"]:\n",
    "        out.append((np.array(sample)-7.3)/8.2)\n",
    "    return {\"x\": out}\n",
    "\n",
    "ds = dataset.map(\n",
    "    fnc,\n",
    "    batched=True,\n",
    "    num_proc=30,\n",
    "    batch_size=100,\n",
    "    load_from_cache_file=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e04e97a770254cf5bd717e2a7fbddbcc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/20 shards):   0%|          | 0/158380 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a11d0bbeb6949038fb4a04d6805228a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/3 shards):   0%|          | 0/19798 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a16cfcff49e4f3fb8027a817ebddd50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/3 shards):   0%|          | 0/19798 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "path = \"/mnt/ceph/users/sgolkar/datasets/astroclip/spectrum_ds\"\n",
    "ds.save_to_disk(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making the joint redshift, spectrum stdalized and bunched dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the dataset\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset('../../astroclip/datasets/legacy_survey.py', \n",
    "                       cache_dir='/mnt/ceph/users/sgolkar/datasets')\n",
    "\n",
    "# Drop the image and redshift features\n",
    "dataset = dataset.remove_columns([\"image\"])\n",
    "\n",
    "# Split the test set 50/50 into test and val\n",
    "test_half_length = len(dataset['test']) // 2\n",
    "test_data = dataset['test'].select(indices=range(test_half_length))\n",
    "val_data = dataset['test'].select(indices=range(test_half_length, len(dataset['test'])))\n",
    "\n",
    "# modify the dataset dict to reflect the split\n",
    "dataset['test'] = test_data\n",
    "dataset['val'] = val_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61ad652f10974f328cdf9dcdd7bece4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=30):   0%|          | 0/158380 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5bb63e034994ac19f05f2695a19d095",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=30):   0%|          | 0/19798 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b9d61f39c1e4bd59278bacb94593c63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=30):   0%|          | 0/19798 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.851979419144681 2.13490672906514 1.4055575607510395\n",
      "28.964371440936596 8.890413099443752 3.8311471087170785\n",
      "2.6224963266261474 3.9564168084707725 1.3600593376579933\n",
      "3.5976514405913194 5.105478611235835 0.6251189150057348\n"
     ]
    }
   ],
   "source": [
    "# Calculating the std distribution\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def fnc(samples):\n",
    "    stds = []\n",
    "    means = []\n",
    "    for sample in samples[\"spectrum\"]:\n",
    "        x = np.array(sample)\n",
    "        means.append(x.mean())\n",
    "        stds.append(x.std())\n",
    "    return {\"std\": stds, \"mean\": means }\n",
    "ds = dataset.map(\n",
    "    fnc,\n",
    "    batched=True,\n",
    "    num_proc=30,\n",
    "    batch_size=100,\n",
    "    load_from_cache_file=False,\n",
    "    remove_columns=[\"spectrum\", \"redshift\"]\n",
    ")\n",
    "\n",
    "train_stds = np.array(ds['train']['std'])\n",
    "val_stds = np.array(ds['val']['std'])\n",
    "test_stds = np.array(ds['test']['std'])\n",
    "\n",
    "print(train_stds.mean(), test_stds.mean(), val_stds.mean())\n",
    "print(train_stds.std(), test_stds.std(), val_stds.std())\n",
    "\n",
    "train_means = np.array(ds['train']['mean'])\n",
    "val_means = np.array(ds['val']['mean'])\n",
    "test_means = np.array(ds['test']['mean'])\n",
    "\n",
    "print(train_means.mean(), test_means.mean(), val_means.mean())\n",
    "print(train_means.std(), test_means.std(), val_means.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': 0.2651120342603547, 'test': 0.20726879838914092, 'val': 0.3198322842947078}\n",
      "{'train': 0.1621082109136878, 'test': 0.12090782935061481, 'val': 0.16460627380227752}\n"
     ]
    }
   ],
   "source": [
    "# and the redshift stats\n",
    "\n",
    "rs = {split: np.array(dataset[split]['redshift']) for split in dataset.keys()}\n",
    "\n",
    "rs_means = {split: rs[split].mean() for split in rs.keys()}\n",
    "rs_stds = {split: rs[split].std() for split in rs.keys()}\n",
    "\n",
    "print(rs_means)\n",
    "print(rs_stds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "166f4f4ef49a425d8ce65d07569d009c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=30):   0%|          | 0/158380 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c0ee580d51a436e92bd9436703e5263",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=30):   0%|          | 0/19798 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d47691601364b1a9b31758d00705647",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=30):   0%|          | 0/19798 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# defining the new dataset\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def slice(x, section_length=10, overlap=5):\n",
    "\n",
    "    start_indices = np.arange(0, len(x) - overlap, section_length - overlap)\n",
    "    sections = [x[start:start + section_length] for start in start_indices]\n",
    "\n",
    "    # If the last section is not of length 'section_length', you can decide whether to keep or discard it\n",
    "    if len(sections[-1]) < section_length:\n",
    "        sections.pop(-1)  # Discard the last section    \n",
    "\n",
    "    return np.concatenate(sections, 1).T\n",
    "\n",
    "\n",
    "def fnc(samples):\n",
    "\n",
    "    out = []\n",
    "\n",
    "    for x, rs in zip(samples[\"spectrum\"], samples[\"redshift\"]):\n",
    "        x = np.array(x)\n",
    "        std, mean = x.std(), x.mean()\n",
    "        # skipping samples that are all zero\n",
    "        if std == 0:\n",
    "            continue\n",
    "        x = (x - mean) / std\n",
    "        x = slice(x, 10, 5)\n",
    "        x = np.pad(x, pad_width=((1,0),(3,0)), mode='constant', constant_values=0)\n",
    "\n",
    "        x[0,0] = (mean-2)/2\n",
    "        x[0,1] = (std-2)/8\n",
    "        x[0,2] = (rs-0.2)/0.15\n",
    "\n",
    "\n",
    "        out.append(x)       \n",
    "\n",
    "    return {\"x\": out}\n",
    "\n",
    "\n",
    "ds = dataset.map(\n",
    "    fnc,\n",
    "    batched=True,\n",
    "    num_proc=30,\n",
    "    batch_size=100,\n",
    "    load_from_cache_file=False,\n",
    "    remove_columns=[\"spectrum\", \"redshift\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/mnt/ceph/users/sgolkar/datasets/astroclip/spec_rs_chunked_ds\"\n",
    "ds.save_to_disk(path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fillm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
