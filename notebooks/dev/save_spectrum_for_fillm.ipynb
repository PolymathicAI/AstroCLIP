{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset('../../astroclip/datasets/legacy_survey.py', \n",
    "                       cache_dir='/mnt/ceph/users/sgolkar/datasets')\n",
    "\n",
    "# Drop the image and redshift features\n",
    "dataset = dataset.remove_columns([\"image\", \"redshift\"])\n",
    "\n",
    "# Split the test set 50/50 into test and val\n",
    "test_half_length = len(dataset['test']) // 2\n",
    "test_data = dataset['test'].select(indices=range(test_half_length))\n",
    "val_data = dataset['test'].select(indices=range(test_half_length, len(dataset['test'])))\n",
    "\n",
    "# modify the dataset dict to reflect the split\n",
    "dataset['test'] = test_data\n",
    "dataset['val'] = val_data\n",
    "\n",
    "dataset = dataset.rename_column('spectrum', 'x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c984bd050d1430d8b3d4019e3200109",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/20 shards):   0%|          | 0/158380 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38224dc2ff334936b20c2e1a6c2f2157",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/3 shards):   0%|          | 0/19798 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47034836647d41999144e98cd87db20b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/3 shards):   0%|          | 0/19798 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "path = \"/mnt/ceph/users/sgolkar/datasets/astroclip/spectrum_ds\"\n",
    "dataset.save_to_disk(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f0cea5e1bc14bb881c471809a150fab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=30):   0%|          | 0/158380 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "972da87b79564fceb17173fc1bf9e9dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=30):   0%|          | 0/19798 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2830341a08142d4a9b6f6fa887be588",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=30):   0%|          | 0/19798 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "def fnc(samples):\n",
    "    out = []\n",
    "    for sample in samples[\"x\"]:\n",
    "        out.append((np.array(sample)-7.3)/8.2)\n",
    "    return {\"x\": out}\n",
    "\n",
    "ds = dataset.map(\n",
    "    fnc,\n",
    "    batched=True,\n",
    "    num_proc=30,\n",
    "    batch_size=100,\n",
    "    load_from_cache_file=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e04e97a770254cf5bd717e2a7fbddbcc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/20 shards):   0%|          | 0/158380 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a11d0bbeb6949038fb4a04d6805228a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/3 shards):   0%|          | 0/19798 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a16cfcff49e4f3fb8027a817ebddd50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/3 shards):   0%|          | 0/19798 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "path = \"/mnt/ceph/users/sgolkar/datasets/astroclip/spectrum_ds\"\n",
    "ds.save_to_disk(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making the joint redshift, spectrum stdalized and bunched dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the dataset\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset('../../astroclip/datasets/legacy_survey.py', \n",
    "                       cache_dir='/mnt/ceph/users/sgolkar/datasets')\n",
    "\n",
    "# Drop the image and redshift features\n",
    "dataset = dataset.remove_columns([\"image\"])\n",
    "\n",
    "# Split the test set 50/50 into test and val\n",
    "test_half_length = len(dataset['test']) // 2\n",
    "test_data = dataset['test'].select(indices=range(test_half_length))\n",
    "val_data = dataset['test'].select(indices=range(test_half_length, len(dataset['test'])))\n",
    "\n",
    "# modify the dataset dict to reflect the split\n",
    "dataset['test'] = test_data\n",
    "dataset['val'] = val_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61ad652f10974f328cdf9dcdd7bece4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=30):   0%|          | 0/158380 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5bb63e034994ac19f05f2695a19d095",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=30):   0%|          | 0/19798 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b9d61f39c1e4bd59278bacb94593c63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=30):   0%|          | 0/19798 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.851979419144681 2.13490672906514 1.4055575607510395\n",
      "28.964371440936596 8.890413099443752 3.8311471087170785\n",
      "2.6224963266261474 3.9564168084707725 1.3600593376579933\n",
      "3.5976514405913194 5.105478611235835 0.6251189150057348\n"
     ]
    }
   ],
   "source": [
    "# Calculating the std distribution\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def fnc(samples):\n",
    "    stds = []\n",
    "    means = []\n",
    "    for sample in samples[\"spectrum\"]:\n",
    "        x = np.array(sample)\n",
    "        means.append(x.mean())\n",
    "        stds.append(x.std())\n",
    "    return {\"std\": stds, \"mean\": means }\n",
    "ds = dataset.map(\n",
    "    fnc,\n",
    "    batched=True,\n",
    "    num_proc=30,\n",
    "    batch_size=100,\n",
    "    load_from_cache_file=False,\n",
    "    remove_columns=[\"spectrum\", \"redshift\"]\n",
    ")\n",
    "\n",
    "train_stds = np.array(ds['train']['std'])\n",
    "val_stds = np.array(ds['val']['std'])\n",
    "test_stds = np.array(ds['test']['std'])\n",
    "\n",
    "print(train_stds.mean(), test_stds.mean(), val_stds.mean())\n",
    "print(train_stds.std(), test_stds.std(), val_stds.std())\n",
    "\n",
    "train_means = np.array(ds['train']['mean'])\n",
    "val_means = np.array(ds['val']['mean'])\n",
    "test_means = np.array(ds['test']['mean'])\n",
    "\n",
    "print(train_means.mean(), test_means.mean(), val_means.mean())\n",
    "print(train_means.std(), test_means.std(), val_means.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': 0.2651120342603547, 'test': 0.20726879838914092, 'val': 0.3198322842947078}\n",
      "{'train': 0.1621082109136878, 'test': 0.12090782935061481, 'val': 0.16460627380227752}\n"
     ]
    }
   ],
   "source": [
    "# and the redshift stats\n",
    "\n",
    "rs = {split: np.array(dataset[split]['redshift']) for split in dataset.keys()}\n",
    "\n",
    "rs_means = {split: rs[split].mean() for split in rs.keys()}\n",
    "rs_stds = {split: rs[split].std() for split in rs.keys()}\n",
    "\n",
    "print(rs_means)\n",
    "print(rs_stds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "166f4f4ef49a425d8ce65d07569d009c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=30):   0%|          | 0/158380 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c0ee580d51a436e92bd9436703e5263",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=30):   0%|          | 0/19798 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d47691601364b1a9b31758d00705647",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=30):   0%|          | 0/19798 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# defining the new dataset\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def slice(x, section_length=10, overlap=5):\n",
    "\n",
    "    start_indices = np.arange(0, len(x) - overlap, section_length - overlap)\n",
    "    sections = [x[start:start + section_length] for start in start_indices]\n",
    "\n",
    "    # If the last section is not of length 'section_length', you can decide whether to keep or discard it\n",
    "    if len(sections[-1]) < section_length:\n",
    "        sections.pop(-1)  # Discard the last section    \n",
    "\n",
    "    return np.concatenate(sections, 1).T\n",
    "\n",
    "\n",
    "def fnc(samples):\n",
    "\n",
    "    out = []\n",
    "\n",
    "    for x, rs in zip(samples[\"spectrum\"], samples[\"redshift\"]):\n",
    "        x = np.array(x)\n",
    "        std, mean = x.std(), x.mean()\n",
    "        # skipping samples that are all zero\n",
    "        if std == 0:\n",
    "            continue\n",
    "        x = (x - mean) / std\n",
    "        x = slice(x, 10, 5)\n",
    "        x = np.pad(x, pad_width=((1,0),(3,0)), mode='constant', constant_values=0)\n",
    "\n",
    "        x[0,0] = (mean-2)/2\n",
    "        x[0,1] = (std-2)/8\n",
    "        x[0,2] = (rs-0.2)/0.15\n",
    "\n",
    "\n",
    "        out.append(x)       \n",
    "\n",
    "    return {\"x\": out}\n",
    "\n",
    "\n",
    "ds = dataset.map(\n",
    "    fnc,\n",
    "    batched=True,\n",
    "    num_proc=30,\n",
    "    batch_size=100,\n",
    "    load_from_cache_file=False,\n",
    "    remove_columns=[\"spectrum\", \"redshift\"]\n",
    ")\n",
    "\n",
    "\n",
    "path = \"/mnt/ceph/users/sgolkar/datasets/astroclip/spec_rs_chunked_ds\"\n",
    "ds.save_to_disk(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ace5328a1afb46559638543ec1beedb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=30):   0%|          | 0/158380 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TimeoutError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/fillm/lib/python3.9/site-packages/datasets/utils/py_utils.py:1373\u001b[0m, in \u001b[0;36miflatmap_unordered\u001b[0;34m(pool, func, kwargs_iterable)\u001b[0m\n\u001b[1;32m   1372\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1373\u001b[0m     \u001b[39myield\u001b[39;00m queue\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49m\u001b[39m0.05\u001b[39;49m)\n\u001b[1;32m   1374\u001b[0m \u001b[39mexcept\u001b[39;00m Empty:\n",
      "File \u001b[0;32m<string>:2\u001b[0m, in \u001b[0;36mget\u001b[0;34m(self, *args, **kwds)\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/fillm/lib/python3.9/site-packages/multiprocess/managers.py:810\u001b[0m, in \u001b[0;36mBaseProxy._callmethod\u001b[0;34m(self, methodname, args, kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m conn\u001b[39m.\u001b[39msend((\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_id, methodname, args, kwds))\n\u001b[0;32m--> 810\u001b[0m kind, result \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49mrecv()\n\u001b[1;32m    812\u001b[0m \u001b[39mif\u001b[39;00m kind \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39m#RETURN\u001b[39m\u001b[39m'\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/envs/fillm/lib/python3.9/site-packages/multiprocess/connection.py:253\u001b[0m, in \u001b[0;36m_ConnectionBase.recv\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_readable()\n\u001b[0;32m--> 253\u001b[0m buf \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_recv_bytes()\n\u001b[1;32m    254\u001b[0m \u001b[39mreturn\u001b[39;00m _ForkingPickler\u001b[39m.\u001b[39mloads(buf\u001b[39m.\u001b[39mgetbuffer())\n",
      "File \u001b[0;32m~/anaconda3/envs/fillm/lib/python3.9/site-packages/multiprocess/connection.py:417\u001b[0m, in \u001b[0;36mConnection._recv_bytes\u001b[0;34m(self, maxsize)\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_recv_bytes\u001b[39m(\u001b[39mself\u001b[39m, maxsize\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m--> 417\u001b[0m     buf \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_recv(\u001b[39m4\u001b[39;49m)\n\u001b[1;32m    418\u001b[0m     size, \u001b[39m=\u001b[39m struct\u001b[39m.\u001b[39munpack(\u001b[39m\"\u001b[39m\u001b[39m!i\u001b[39m\u001b[39m\"\u001b[39m, buf\u001b[39m.\u001b[39mgetvalue())\n",
      "File \u001b[0;32m~/anaconda3/envs/fillm/lib/python3.9/site-packages/multiprocess/connection.py:382\u001b[0m, in \u001b[0;36mConnection._recv\u001b[0;34m(self, size, read)\u001b[0m\n\u001b[1;32m    381\u001b[0m \u001b[39mwhile\u001b[39;00m remaining \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m--> 382\u001b[0m     chunk \u001b[39m=\u001b[39m read(handle, remaining)\n\u001b[1;32m    383\u001b[0m     n \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(chunk)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTimeoutError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/mnt/home/sgolkar/projects/AstroCLIP/notebooks/dev/save_spectrum_for_fillm.ipynb Cell 10\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bws-cca/mnt/home/sgolkar/projects/AstroCLIP/notebooks/dev/save_spectrum_for_fillm.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=34'>35</a>\u001b[0m         out\u001b[39m.\u001b[39mappend(x)       \n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bws-cca/mnt/home/sgolkar/projects/AstroCLIP/notebooks/dev/save_spectrum_for_fillm.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=36'>37</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m {\u001b[39m\"\u001b[39m\u001b[39mx\u001b[39m\u001b[39m\"\u001b[39m: out}\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bws-cca/mnt/home/sgolkar/projects/AstroCLIP/notebooks/dev/save_spectrum_for_fillm.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=39'>40</a>\u001b[0m ds \u001b[39m=\u001b[39m dataset\u001b[39m.\u001b[39;49mmap(\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bws-cca/mnt/home/sgolkar/projects/AstroCLIP/notebooks/dev/save_spectrum_for_fillm.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=40'>41</a>\u001b[0m     fnc,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bws-cca/mnt/home/sgolkar/projects/AstroCLIP/notebooks/dev/save_spectrum_for_fillm.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=41'>42</a>\u001b[0m     batched\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bws-cca/mnt/home/sgolkar/projects/AstroCLIP/notebooks/dev/save_spectrum_for_fillm.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=42'>43</a>\u001b[0m     num_proc\u001b[39m=\u001b[39;49m\u001b[39m30\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bws-cca/mnt/home/sgolkar/projects/AstroCLIP/notebooks/dev/save_spectrum_for_fillm.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=43'>44</a>\u001b[0m     batch_size\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bws-cca/mnt/home/sgolkar/projects/AstroCLIP/notebooks/dev/save_spectrum_for_fillm.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=44'>45</a>\u001b[0m     load_from_cache_file\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bws-cca/mnt/home/sgolkar/projects/AstroCLIP/notebooks/dev/save_spectrum_for_fillm.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=45'>46</a>\u001b[0m     remove_columns\u001b[39m=\u001b[39;49m[\u001b[39m\"\u001b[39;49m\u001b[39mspectrum\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mredshift\u001b[39;49m\u001b[39m\"\u001b[39;49m]\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bws-cca/mnt/home/sgolkar/projects/AstroCLIP/notebooks/dev/save_spectrum_for_fillm.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=46'>47</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bws-cca/mnt/home/sgolkar/projects/AstroCLIP/notebooks/dev/save_spectrum_for_fillm.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=49'>50</a>\u001b[0m path \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m/mnt/ceph/users/sgolkar/datasets/astroclip/spec_chunked_ds\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bws-cca/mnt/home/sgolkar/projects/AstroCLIP/notebooks/dev/save_spectrum_for_fillm.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=50'>51</a>\u001b[0m ds\u001b[39m.\u001b[39msave_to_disk(path)\n",
      "File \u001b[0;32m~/anaconda3/envs/fillm/lib/python3.9/site-packages/datasets/dataset_dict.py:853\u001b[0m, in \u001b[0;36mDatasetDict.map\u001b[0;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_names, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, desc)\u001b[0m\n\u001b[1;32m    850\u001b[0m \u001b[39mif\u001b[39;00m cache_file_names \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    851\u001b[0m     cache_file_names \u001b[39m=\u001b[39m {k: \u001b[39mNone\u001b[39;00m \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m}\n\u001b[1;32m    852\u001b[0m \u001b[39mreturn\u001b[39;00m DatasetDict(\n\u001b[0;32m--> 853\u001b[0m     {\n\u001b[1;32m    854\u001b[0m         k: dataset\u001b[39m.\u001b[39mmap(\n\u001b[1;32m    855\u001b[0m             function\u001b[39m=\u001b[39mfunction,\n\u001b[1;32m    856\u001b[0m             with_indices\u001b[39m=\u001b[39mwith_indices,\n\u001b[1;32m    857\u001b[0m             with_rank\u001b[39m=\u001b[39mwith_rank,\n\u001b[1;32m    858\u001b[0m             input_columns\u001b[39m=\u001b[39minput_columns,\n\u001b[1;32m    859\u001b[0m             batched\u001b[39m=\u001b[39mbatched,\n\u001b[1;32m    860\u001b[0m             batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[1;32m    861\u001b[0m             drop_last_batch\u001b[39m=\u001b[39mdrop_last_batch,\n\u001b[1;32m    862\u001b[0m             remove_columns\u001b[39m=\u001b[39mremove_columns,\n\u001b[1;32m    863\u001b[0m             keep_in_memory\u001b[39m=\u001b[39mkeep_in_memory,\n\u001b[1;32m    864\u001b[0m             load_from_cache_file\u001b[39m=\u001b[39mload_from_cache_file,\n\u001b[1;32m    865\u001b[0m             cache_file_name\u001b[39m=\u001b[39mcache_file_names[k],\n\u001b[1;32m    866\u001b[0m             writer_batch_size\u001b[39m=\u001b[39mwriter_batch_size,\n\u001b[1;32m    867\u001b[0m             features\u001b[39m=\u001b[39mfeatures,\n\u001b[1;32m    868\u001b[0m             disable_nullable\u001b[39m=\u001b[39mdisable_nullable,\n\u001b[1;32m    869\u001b[0m             fn_kwargs\u001b[39m=\u001b[39mfn_kwargs,\n\u001b[1;32m    870\u001b[0m             num_proc\u001b[39m=\u001b[39mnum_proc,\n\u001b[1;32m    871\u001b[0m             desc\u001b[39m=\u001b[39mdesc,\n\u001b[1;32m    872\u001b[0m         )\n\u001b[1;32m    873\u001b[0m         \u001b[39mfor\u001b[39;00m k, dataset \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems()\n\u001b[1;32m    874\u001b[0m     }\n\u001b[1;32m    875\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/fillm/lib/python3.9/site-packages/datasets/dataset_dict.py:854\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    850\u001b[0m \u001b[39mif\u001b[39;00m cache_file_names \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    851\u001b[0m     cache_file_names \u001b[39m=\u001b[39m {k: \u001b[39mNone\u001b[39;00m \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m}\n\u001b[1;32m    852\u001b[0m \u001b[39mreturn\u001b[39;00m DatasetDict(\n\u001b[1;32m    853\u001b[0m     {\n\u001b[0;32m--> 854\u001b[0m         k: dataset\u001b[39m.\u001b[39;49mmap(\n\u001b[1;32m    855\u001b[0m             function\u001b[39m=\u001b[39;49mfunction,\n\u001b[1;32m    856\u001b[0m             with_indices\u001b[39m=\u001b[39;49mwith_indices,\n\u001b[1;32m    857\u001b[0m             with_rank\u001b[39m=\u001b[39;49mwith_rank,\n\u001b[1;32m    858\u001b[0m             input_columns\u001b[39m=\u001b[39;49minput_columns,\n\u001b[1;32m    859\u001b[0m             batched\u001b[39m=\u001b[39;49mbatched,\n\u001b[1;32m    860\u001b[0m             batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[1;32m    861\u001b[0m             drop_last_batch\u001b[39m=\u001b[39;49mdrop_last_batch,\n\u001b[1;32m    862\u001b[0m             remove_columns\u001b[39m=\u001b[39;49mremove_columns,\n\u001b[1;32m    863\u001b[0m             keep_in_memory\u001b[39m=\u001b[39;49mkeep_in_memory,\n\u001b[1;32m    864\u001b[0m             load_from_cache_file\u001b[39m=\u001b[39;49mload_from_cache_file,\n\u001b[1;32m    865\u001b[0m             cache_file_name\u001b[39m=\u001b[39;49mcache_file_names[k],\n\u001b[1;32m    866\u001b[0m             writer_batch_size\u001b[39m=\u001b[39;49mwriter_batch_size,\n\u001b[1;32m    867\u001b[0m             features\u001b[39m=\u001b[39;49mfeatures,\n\u001b[1;32m    868\u001b[0m             disable_nullable\u001b[39m=\u001b[39;49mdisable_nullable,\n\u001b[1;32m    869\u001b[0m             fn_kwargs\u001b[39m=\u001b[39;49mfn_kwargs,\n\u001b[1;32m    870\u001b[0m             num_proc\u001b[39m=\u001b[39;49mnum_proc,\n\u001b[1;32m    871\u001b[0m             desc\u001b[39m=\u001b[39;49mdesc,\n\u001b[1;32m    872\u001b[0m         )\n\u001b[1;32m    873\u001b[0m         \u001b[39mfor\u001b[39;00m k, dataset \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems()\n\u001b[1;32m    874\u001b[0m     }\n\u001b[1;32m    875\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/fillm/lib/python3.9/site-packages/datasets/arrow_dataset.py:592\u001b[0m, in \u001b[0;36mtransmit_tasks.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    590\u001b[0m     \u001b[39mself\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mDataset\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mpop(\u001b[39m\"\u001b[39m\u001b[39mself\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    591\u001b[0m \u001b[39m# apply actual function\u001b[39;00m\n\u001b[0;32m--> 592\u001b[0m out: Union[\u001b[39m\"\u001b[39m\u001b[39mDataset\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mDatasetDict\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m func(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    593\u001b[0m datasets: List[\u001b[39m\"\u001b[39m\u001b[39mDataset\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(out\u001b[39m.\u001b[39mvalues()) \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(out, \u001b[39mdict\u001b[39m) \u001b[39melse\u001b[39;00m [out]\n\u001b[1;32m    594\u001b[0m \u001b[39mfor\u001b[39;00m dataset \u001b[39min\u001b[39;00m datasets:\n\u001b[1;32m    595\u001b[0m     \u001b[39m# Remove task templates if a column mapping of the template is no longer valid\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/fillm/lib/python3.9/site-packages/datasets/arrow_dataset.py:557\u001b[0m, in \u001b[0;36mtransmit_format.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    550\u001b[0m self_format \u001b[39m=\u001b[39m {\n\u001b[1;32m    551\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtype\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_type,\n\u001b[1;32m    552\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mformat_kwargs\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_kwargs,\n\u001b[1;32m    553\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mcolumns\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_columns,\n\u001b[1;32m    554\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39moutput_all_columns\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output_all_columns,\n\u001b[1;32m    555\u001b[0m }\n\u001b[1;32m    556\u001b[0m \u001b[39m# apply actual function\u001b[39;00m\n\u001b[0;32m--> 557\u001b[0m out: Union[\u001b[39m\"\u001b[39m\u001b[39mDataset\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mDatasetDict\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m func(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    558\u001b[0m datasets: List[\u001b[39m\"\u001b[39m\u001b[39mDataset\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(out\u001b[39m.\u001b[39mvalues()) \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(out, \u001b[39mdict\u001b[39m) \u001b[39melse\u001b[39;00m [out]\n\u001b[1;32m    559\u001b[0m \u001b[39m# re-apply format to the output\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/fillm/lib/python3.9/site-packages/datasets/arrow_dataset.py:3189\u001b[0m, in \u001b[0;36mDataset.map\u001b[0;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, suffix_template, new_fingerprint, desc)\u001b[0m\n\u001b[1;32m   3182\u001b[0m logger\u001b[39m.\u001b[39minfo(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mSpawning \u001b[39m\u001b[39m{\u001b[39;00mnum_proc\u001b[39m}\u001b[39;00m\u001b[39m processes\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   3183\u001b[0m \u001b[39mwith\u001b[39;00m logging\u001b[39m.\u001b[39mtqdm(\n\u001b[1;32m   3184\u001b[0m     disable\u001b[39m=\u001b[39m\u001b[39mnot\u001b[39;00m logging\u001b[39m.\u001b[39mis_progress_bar_enabled(),\n\u001b[1;32m   3185\u001b[0m     unit\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m examples\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   3186\u001b[0m     total\u001b[39m=\u001b[39mpbar_total,\n\u001b[1;32m   3187\u001b[0m     desc\u001b[39m=\u001b[39m(desc \u001b[39mor\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mMap\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39m+\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m (num_proc=\u001b[39m\u001b[39m{\u001b[39;00mnum_proc\u001b[39m}\u001b[39;00m\u001b[39m)\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   3188\u001b[0m ) \u001b[39mas\u001b[39;00m pbar:\n\u001b[0;32m-> 3189\u001b[0m     \u001b[39mfor\u001b[39;00m rank, done, content \u001b[39min\u001b[39;00m iflatmap_unordered(\n\u001b[1;32m   3190\u001b[0m         pool, Dataset\u001b[39m.\u001b[39m_map_single, kwargs_iterable\u001b[39m=\u001b[39mkwargs_per_job\n\u001b[1;32m   3191\u001b[0m     ):\n\u001b[1;32m   3192\u001b[0m         \u001b[39mif\u001b[39;00m done:\n\u001b[1;32m   3193\u001b[0m             shards_done \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/fillm/lib/python3.9/site-packages/datasets/utils/py_utils.py:1387\u001b[0m, in \u001b[0;36miflatmap_unordered\u001b[0;34m(pool, func, kwargs_iterable)\u001b[0m\n\u001b[1;32m   1384\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m   1385\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m pool_changed:\n\u001b[1;32m   1386\u001b[0m         \u001b[39m# we get the result in case there's an error to raise\u001b[39;00m\n\u001b[0;32m-> 1387\u001b[0m         [async_result\u001b[39m.\u001b[39mget(timeout\u001b[39m=\u001b[39m\u001b[39m0.05\u001b[39m) \u001b[39mfor\u001b[39;00m async_result \u001b[39min\u001b[39;00m async_results]\n",
      "File \u001b[0;32m~/anaconda3/envs/fillm/lib/python3.9/site-packages/datasets/utils/py_utils.py:1387\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1384\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m   1385\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m pool_changed:\n\u001b[1;32m   1386\u001b[0m         \u001b[39m# we get the result in case there's an error to raise\u001b[39;00m\n\u001b[0;32m-> 1387\u001b[0m         [async_result\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49m\u001b[39m0.05\u001b[39;49m) \u001b[39mfor\u001b[39;00m async_result \u001b[39min\u001b[39;00m async_results]\n",
      "File \u001b[0;32m~/anaconda3/envs/fillm/lib/python3.9/site-packages/multiprocess/pool.py:767\u001b[0m, in \u001b[0;36mApplyResult.get\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    765\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwait(timeout)\n\u001b[1;32m    766\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mready():\n\u001b[0;32m--> 767\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m\n\u001b[1;32m    768\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_success:\n\u001b[1;32m    769\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_value\n",
      "\u001b[0;31mTimeoutError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# defining the new dataset\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def slice(x, section_length=10, overlap=5):\n",
    "\n",
    "    start_indices = np.arange(0, len(x) - overlap, section_length - overlap)\n",
    "    sections = [x[start:start + section_length] for start in start_indices]\n",
    "\n",
    "    # If the last section is not of length 'section_length', you can decide whether to keep or discard it\n",
    "    if len(sections[-1]) < section_length:\n",
    "        sections.pop(-1)  # Discard the last section    \n",
    "\n",
    "    return np.concatenate(sections, 1).T\n",
    "\n",
    "\n",
    "def fnc(samples):\n",
    "\n",
    "    out = []\n",
    "\n",
    "    for x, rs in zip(samples[\"spectrum\"], samples[\"redshift\"]):\n",
    "        x = np.array(x)\n",
    "        std, mean = x.std(), x.mean()\n",
    "        # skipping samples that are all zero\n",
    "        if std == 0:\n",
    "            continue\n",
    "        x = (x - mean) / std\n",
    "        x = slice(x, 20, 10)\n",
    "        x = np.pad(x, pad_width=((1,0),(2,0)), mode='constant', constant_values=0)\n",
    "\n",
    "        x[0,0] = (mean-2)/2\n",
    "        x[0,1] = (std-2)/8\n",
    "\n",
    "\n",
    "        out.append(x)       \n",
    "\n",
    "    return {\"x\": out}\n",
    "\n",
    "\n",
    "ds = dataset.map(\n",
    "    fnc,\n",
    "    batched=True,\n",
    "    num_proc=30,\n",
    "    batch_size=100,\n",
    "    load_from_cache_file=False,\n",
    "    remove_columns=[\"spectrum\", \"redshift\"]\n",
    ")\n",
    "\n",
    "\n",
    "path = \"/mnt/ceph/users/sgolkar/datasets/astroclip/spec_chunked_ds\"\n",
    "ds.save_to_disk(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fillm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
