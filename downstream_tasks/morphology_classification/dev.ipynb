{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/home/lparker/Documents/AstroFoundationModel/AstroDino/dinov2/dinov2/layers/swiglu_ffn.py:43: UserWarning: xFormers is available (SwiGLU)\n",
      "  warnings.warn(\"xFormers is available (SwiGLU)\")\n",
      "/mnt/home/lparker/Documents/AstroFoundationModel/AstroDino/dinov2/dinov2/layers/attention.py:27: UserWarning: xFormers is available (Attention)\n",
      "  warnings.warn(\"xFormers is available (Attention)\")\n",
      "/mnt/home/lparker/Documents/AstroFoundationModel/AstroDino/dinov2/dinov2/layers/block.py:33: UserWarning: xFormers is available (Block)\n",
      "  warnings.warn(\"xFormers is available (Block)\")\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os, sys\n",
    "import torch\n",
    "import numpy as np\n",
    "import h5py\n",
    "from tqdm import tqdm\n",
    "from helpers import process, to_pil_image, dr2_rgb\n",
    "from PIL import Image as im\n",
    "from astropy.table import Table, join, vstack\n",
    "from astropy.coordinates import SkyCoord, match_coordinates_sky\n",
    "from astropy import units as u\n",
    "from torchvision.transforms import Compose, ToTensor, Normalize, Resize, InterpolationMode, CenterCrop\n",
    "sys.path.insert(0, os.path.abspath('/mnt/home/lparker/Documents/AstroFoundationModel/AstroDino/dinov2/'))\n",
    "sys.path.insert(0, os.path.abspath('/mnt/home/lparker/Documents/AstroFoundationModel/AstroDino/'))\n",
    "from dinov2.utils.config import setup\n",
    "from dinov2.models import build_model_from_cfg\n",
    "from dinov2.fsdp import FSDPCheckpointer\n",
    "from dinov2.train.ssl_meta_arch import SSLMetaArch\n",
    "from dinov2.eval.setup import setup_and_build_model\n",
    "from dinov2.data.transforms import make_normalize_transform\n",
    "\n",
    "# Image Files locations\n",
    "files_north = [os.path.join('/mnt/ceph/users/polymathic/external_data/astro/DECALS_Stein_et_al/north/', 'images_npix152_0%02d000000_0%02d000000.h5'%(i,i+1)) for i in range(10)]\n",
    "files_south = [os.path.join('/mnt/ceph/users/polymathic/external_data/astro/DECALS_Stein_et_al/south/', 'images_npix152_0%02d000000_0%02d000000.h5'%(i,i+1)) for i in range(62)]\n",
    "\n",
    "# Classifications location\n",
    "gz5_decals_path = '/mnt/home/lparker/ceph/gz_decals_volunteers_5.csv'\n",
    "gz2_sdss_path = '/mnt/home/lparker/ceph/gz2_hart16.csv'\n",
    "\n",
    "# Transformations for models\n",
    "MEAN = (0.485, 0.456, 0.406)\n",
    "STD = (0.229, 0.224, 0.225)\n",
    "img_transforms = Compose([to_pil_image,\n",
    "                  Resize(152, InterpolationMode.BICUBIC),\n",
    "                  ToTensor(),\n",
    "                  CenterCrop(144),\n",
    "                  Normalize(MEAN, STD)])\n",
    "\n",
    "class config:\n",
    "    output_dir = '/mnt/home/lparker/ceph/dino_training'\n",
    "    config_file = '../astrodino/configs/ssl_default_config.yaml'\n",
    "    pretrained_weights = '/mnt/home/lparker/ceph/astrodino/vitl12_simplified_better_wd/training_199999/teacher_checkpoint.pth'\n",
    "    opts = []\n",
    "\n",
    "def get_paired_classifications(sky, gz_survey):\n",
    "    if sky == 'south': files = files_south\n",
    "    elif sky == 'north': files = files_north\n",
    "    else: raise ValueError('Not supported sky type, choose south or north')\n",
    "    \n",
    "    if gz_survey == 'gz2': classifications_path = gz2_sdss_path\n",
    "    elif gz_survey == 'gz5': classifications_path = gz5_decals_path\n",
    "    else: raise ValueError('Not supported gz_survey type, choose gz2 or gz5')\n",
    "\n",
    "    print(f'Sky type is {sky}, survey type is {gz_survey}', flush=True)\n",
    "    \n",
    "    morphologies = Table.read(classifications_path, format='ascii')\n",
    "    \n",
    "    ra_list = []\n",
    "    dec_list = []\n",
    "    index_list = []\n",
    "    file_list = []\n",
    "\n",
    "    print('Processing files', flush=True)\n",
    "    for i, file in enumerate(tqdm(files)):\n",
    "        with h5py.File(file, 'r') as f:\n",
    "            ra = f['ra'][:]\n",
    "            dec = f['dec'][:]\n",
    "\n",
    "            # Append data to lists\n",
    "            ra_list.extend(ra)\n",
    "            dec_list.extend(dec)\n",
    "            file_list.extend([file]*len(ra))\n",
    "            index_list.extend(range(0, len(ra)))\n",
    "              \n",
    "    positions = Table([ra_list, dec_list, index_list, file_list], names=('ra', 'dec', 'index', 'file'))\n",
    "    \n",
    "    table1 = positions\n",
    "    table2 = morphologies\n",
    "\n",
    "    coords1 = SkyCoord(ra=table1['ra']*u.degree, dec=table1['dec']*u.degree)\n",
    "    coords2 = SkyCoord(ra=table2['ra']*u.degree, dec=table2['dec']*u.degree)\n",
    "\n",
    "    print('Matching coordinates', flush=True)\n",
    "    idx, d2d, d3d = coords1.match_to_catalog_sky(coords2).to(u.arcsec).value\n",
    "\n",
    "    max_sep = 0.5 * u.arcsec\n",
    "    sep_constraint = d2d < max_sep\n",
    "\n",
    "    classifications = table2[idx[sep_constraint]]\n",
    "    positions_matched = table1[sep_constraint]\n",
    "    classifications['index'] = np.array(positions_matched['index'])\n",
    "    classifications['file'] = np.array(positions_matched['file'])\n",
    "    classifications['image'] = np.zeros((len(classifications), 3, 152, 152))\n",
    "    \n",
    "    print('Generating catalog with images', flush=True)\n",
    "    for i, file in enumerate(files):\n",
    "        print(f'Processing file {i+1}/{len(files)}', flush=True)\n",
    "        images = []\n",
    "        with h5py.File(file, 'r') as f:\n",
    "            for k, entry in enumerate(tqdm(classifications)):\n",
    "                if entry['file'] != file: continue\n",
    "                index = entry['index']\n",
    "                classifications[k]['image'] = f['images'][index]        \n",
    "    return classifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sky type is north, survey type is gz5\n",
      "Processing files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:03<00:00,  2.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matching coordinates\n"
     ]
    }
   ],
   "source": [
    "classifications = get_paired_classifications('north', 'gz5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Pretrained Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I20240422 16:09:39 1391273 dinov2 config.py:59] git:\n",
      "  sha: 2302b6bf46953431b969155307b9bed152754069, status: clean, branch: main\n",
      "\n",
      "I20240422 16:09:39 1391273 dinov2 config.py:60] opts: ['train.output_dir=/mnt/home/lparker/ceph/dino_training']\n",
      "output_dir: /mnt/home/lparker/ceph/dino_training\n",
      "I20240422 16:09:39 1391273 dinov2 config.py:26] sqrt scaling learning rate; base: 0.002, new: 0.0005\n",
      "I20240422 16:09:39 1391273 dinov2 config.py:33] MODEL:\n",
      "  WEIGHTS: ''\n",
      "compute_precision:\n",
      "  grad_scaler: true\n",
      "  teacher:\n",
      "    backbone:\n",
      "      sharding_strategy: SHARD_GRAD_OP\n",
      "      mixed_precision:\n",
      "        param_dtype: fp16\n",
      "        reduce_dtype: fp16\n",
      "        buffer_dtype: fp32\n",
      "    dino_head:\n",
      "      sharding_strategy: SHARD_GRAD_OP\n",
      "      mixed_precision:\n",
      "        param_dtype: fp16\n",
      "        reduce_dtype: fp16\n",
      "        buffer_dtype: fp32\n",
      "    ibot_head:\n",
      "      sharding_strategy: SHARD_GRAD_OP\n",
      "      mixed_precision:\n",
      "        param_dtype: fp16\n",
      "        reduce_dtype: fp16\n",
      "        buffer_dtype: fp32\n",
      "  student:\n",
      "    backbone:\n",
      "      sharding_strategy: SHARD_GRAD_OP\n",
      "      mixed_precision:\n",
      "        param_dtype: fp16\n",
      "        reduce_dtype: fp16\n",
      "        buffer_dtype: fp32\n",
      "    dino_head:\n",
      "      sharding_strategy: SHARD_GRAD_OP\n",
      "      mixed_precision:\n",
      "        param_dtype: fp16\n",
      "        reduce_dtype: fp32\n",
      "        buffer_dtype: fp32\n",
      "    ibot_head:\n",
      "      sharding_strategy: SHARD_GRAD_OP\n",
      "      mixed_precision:\n",
      "        param_dtype: fp16\n",
      "        reduce_dtype: fp32\n",
      "        buffer_dtype: fp32\n",
      "dino:\n",
      "  loss_weight: 1.0\n",
      "  head_n_prototypes: 65536\n",
      "  head_bottleneck_dim: 256\n",
      "  head_nlayers: 3\n",
      "  head_hidden_dim: 2048\n",
      "  koleo_loss_weight: 0.1\n",
      "ibot:\n",
      "  loss_weight: 1.0\n",
      "  mask_sample_probability: 0.5\n",
      "  mask_ratio_min_max:\n",
      "  - 0.1\n",
      "  - 0.5\n",
      "  separate_head: false\n",
      "  head_n_prototypes: 65536\n",
      "  head_bottleneck_dim: 256\n",
      "  head_nlayers: 3\n",
      "  head_hidden_dim: 2048\n",
      "train:\n",
      "  batch_size_per_gpu: 64\n",
      "  dataset_path: LegacySurvey:split=train:root=/mnt/home/flanusse/ceph:extra=\"\"\n",
      "  output_dir: /mnt/home/lparker/ceph/dino_training\n",
      "  saveckp_freq: 20\n",
      "  seed: 0\n",
      "  num_workers: 10\n",
      "  OFFICIAL_EPOCH_LENGTH: 1250\n",
      "  cache_dataset: true\n",
      "  centering: centering\n",
      "student:\n",
      "  arch: vit_large\n",
      "  patch_size: 12\n",
      "  drop_path_rate: 0.3\n",
      "  layerscale: 1.0e-05\n",
      "  drop_path_uniform: true\n",
      "  pretrained_weights: ''\n",
      "  ffn_layer: mlp\n",
      "  block_chunks: 4\n",
      "  qkv_bias: true\n",
      "  proj_bias: true\n",
      "  ffn_bias: true\n",
      "  num_register_tokens: 0\n",
      "  interpolate_antialias: false\n",
      "  interpolate_offset: 0.1\n",
      "teacher:\n",
      "  momentum_teacher: 0.992\n",
      "  final_momentum_teacher: 1\n",
      "  warmup_teacher_temp: 0.04\n",
      "  teacher_temp: 0.07\n",
      "  warmup_teacher_temp_epochs: 30\n",
      "optim:\n",
      "  epochs: 100\n",
      "  weight_decay: 0.04\n",
      "  weight_decay_end: 0.04\n",
      "  base_lr: 0.002\n",
      "  lr: 0.0005\n",
      "  warmup_epochs: 10\n",
      "  min_lr: 1.0e-06\n",
      "  clip_grad: 3.0\n",
      "  freeze_last_layer_epochs: 1\n",
      "  scaling_rule: sqrt_wrt_1024\n",
      "  patch_embed_lr_mult: 0.2\n",
      "  layerwise_decay: 0.9\n",
      "  adamw_beta1: 0.9\n",
      "  adamw_beta2: 0.999\n",
      "crops:\n",
      "  global_crops_scale:\n",
      "  - 0.8\n",
      "  - 1.0\n",
      "  local_crops_number: 8\n",
      "  local_crops_scale:\n",
      "  - 0.4\n",
      "  - 0.6\n",
      "  global_crops_size: 144\n",
      "  local_crops_size: 60\n",
      "evaluation:\n",
      "  eval_period_iterations: 12500\n",
      "\n",
      "I20240422 16:09:39 1391273 dinov2 vision_transformer.py:122] using MLP layer as FFN\n",
      "I20240422 16:09:52 1391273 dinov2 utils.py:26] Take key teacher in provided checkpoint dict\n",
      "I20240422 16:09:52 1391273 dinov2 utils.py:33] Pretrained weights found at /mnt/home/lparker/ceph/astrodino/vitl12_simplified_better_wd/training_199999/teacher_checkpoint.pth and loaded with msg: _IncompatibleKeys(missing_keys=[], unexpected_keys=['register_tokens', 'dino_head.mlp.0.weight', 'dino_head.mlp.0.bias', 'dino_head.mlp.2.weight', 'dino_head.mlp.2.bias', 'dino_head.mlp.4.weight', 'dino_head.mlp.4.bias', 'dino_head.last_layer.weight_g', 'dino_head.last_layer.weight_v'])\n",
      "Number of parameters in image model: 306,630,656\n",
      "Number of parameters in spectrum model: 43,177,750\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '/mnt/home/lparker/Documents/AstroFoundationModel/AstroCLIP_legacy/notebooks/tutorial/')\n",
    "\n",
    "from leopoldo import AstroCLIP, OutputExtractor, seq_decoder, config, forward_im\n",
    "from tutorial_helpers import load_model_from_ckpt, forward\n",
    "from torchvision.transforms import Compose, Normalize\n",
    "import copy\n",
    "\n",
    "class config:\n",
    "    output_dir = '/mnt/home/lparker/ceph/dino_training'\n",
    "    config_file = '/mnt/home/lparker/Documents/AstroFoundationModel/AstroDino_legacy/astrodino/configs/ssl_default_config.yaml'\n",
    "    pretrained_weights = '/mnt/home/lparker/ceph/astrodino/vitl12_simplified_better_wd/training_199999/teacher_checkpoint.pth'\n",
    "    opts = []\n",
    "\n",
    "# Specify transforms\n",
    "MEAN = (0.485, 0.456, 0.406) # Imagenet default mean\n",
    "STD = (0.229, 0.224, 0.225) # Imagenet default std        \n",
    "img_transforms = Compose([Normalize(MEAN, STD)])\n",
    "\n",
    "# set this\n",
    "embed_dim = 512\n",
    "\n",
    "# Define DINO model\n",
    "img_model, dtype = setup_and_build_model(config())\n",
    "\n",
    "DINO = copy.deepcopy(img_model)\n",
    "\n",
    "# Extract encoder_q from Moco_v2 model\n",
    "img_model.forward = forward_im.__get__(img_model)\n",
    "img_model = OutputExtractor(img_model,embed_dim=embed_dim, freeze_backbone=True)\n",
    "num_params = np.sum(np.fromiter((p.numel() for p in img_model.parameters()), int))\n",
    "print(f\"Number of parameters in image model: {num_params:,}\")\n",
    "\n",
    "# The model is saved in the Seqformer branch of Fi-LLM\n",
    "model_path = \"/mnt/home/sgolkar/ceph/saves/fillm/run-seqformer-2708117\"\n",
    "out = load_model_from_ckpt(model_path)\n",
    "config = out['config']\n",
    "spec_model = out['model']\n",
    "spec_model.forward = forward.__get__(spec_model, type(img_model))\n",
    "num_params = np.sum(np.fromiter((p.numel() for p in spec_model.parameters()), int))\n",
    "print(f\"Number of parameters in spectrum model: {num_params:,}\")\n",
    "\n",
    "# Define image and spectrum encoders\n",
    "image_encoder = img_model\n",
    "spectrum_encoder = seq_decoder(model=spec_model, embed_dim=embed_dim, freeze_backbone=True)   \n",
    "\n",
    "# Set up AstroCLIP\n",
    "astroclip = AstroCLIP(image_encoder, spectrum_encoder, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = '/mnt/home/lparker/Documents/AstroFoundationModel/AstroCLIP_legacy/notebooks/tutorial/astroclip-clip-explore/03x73csv/checkpoints/epoch=14-step=2310.ckpt'\n",
    "\n",
    "ckpt = torch.load(file)\n",
    "astroclip.load_state_dict(ckpt['state_dict'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightning as L\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "from PIL import Image as im\n",
    "\n",
    "def sdss_rgb(imgs, bands, scales=None,\n",
    "             m = 0.02):\n",
    "    rgbscales = {'u': (2,1.5), #1.0,\n",
    "                 'g': (2,2.5),\n",
    "                 'r': (1,1.5),\n",
    "                 'i': (0,1.0),\n",
    "                 'z': (0,0.4), #0.3\n",
    "                 }\n",
    "    if scales is not None:\n",
    "        rgbscales.update(scales)\n",
    "\n",
    "    I = 0\n",
    "    for img,band in zip(imgs, bands):\n",
    "        plane,scale = rgbscales[band]\n",
    "        img = torch.maximum(torch.tensor(0), img * scale + m)\n",
    "        I = I + img\n",
    "    I /= len(bands)\n",
    "    Q = 20\n",
    "    fI = torch.arcsinh(Q * I) / torch.sqrt(torch.tensor(Q))\n",
    "    I += (I == 0.) * 1e-6\n",
    "    H,W = I.shape\n",
    "    rgb = torch.zeros((H,W,3)).to(torch.float32)\n",
    "    for img,band in zip(imgs, bands):\n",
    "        plane,scale = rgbscales[band]\n",
    "        rgb[:,:,plane] = (img * scale + m) * fI / I\n",
    "    rgb = torch.clip(rgb, 0, 1)\n",
    "    return rgb\n",
    "\n",
    "def dr2_rgb(rimgs, bands, **ignored):\n",
    "    return sdss_rgb(rimgs, bands, scales=dict(g=(2,6.0), r=(1,3.4), z=(0,2.2)), m=0.03)\n",
    "\n",
    "class toRGB(transforms.ToTensor):\n",
    "    def __init__(self, bands, scales=None, m=0.02):\n",
    "        self.bands = bands\n",
    "        self.scales = scales\n",
    "        self.m = m\n",
    "\n",
    "    def __call__(self, rimgs):\n",
    "        if len(rimgs.shape) == 3:\n",
    "            return dr2_rgb(rimgs.T, self.bands).T\n",
    "        if len(rimgs.shape) == 4:\n",
    "            img_outs = []\n",
    "            for img in rimgs:\n",
    "                img_outs.append(dr2_rgb(img.T, self.bands).T[None, :, :, :])\n",
    "            return torch.concatenate(img_outs)\n",
    "\n",
    "\n",
    "MEAN, STD = (0.485, 0.456, 0.406), (0.229, 0.224, 0.225)\n",
    "\n",
    "img_transforms = Compose([\n",
    "    Resize(152, InterpolationMode.BICUBIC),\n",
    "    ToTensor(),\n",
    "    CenterCrop(144),\n",
    "    Normalize(MEAN, STD)])\n",
    "\n",
    "to_rgb = toRGB(bands=[\"g\", \"r\", \"z\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import lightning as L\n",
    "# from pl_bolts.models.self_supervised import Moco_v2\n",
    "\n",
    "# class OutputExtractor(L.LightningModule):\n",
    "#     \"\"\"\n",
    "#     Pass data through network to extract model outputs\n",
    "#     \"\"\"\n",
    "#     def __init__(self, backbone: torch.nn.Module):    \n",
    "#         super(OutputExtractor, self).__init__()\n",
    "#         self.backbone = backbone\n",
    "#         self.backbone.eval()\n",
    "\n",
    "#     def forward(self, batch):\n",
    "#         x = batch\n",
    "#         z_emb = self.backbone(x)\n",
    "#         return z_emb\n",
    "    \n",
    "#     def predict(self, batch, batch_idx: int, dataloader_idx: int=None):\n",
    "#         return self(batch)\n",
    "\n",
    "# # Extract encoder_q from Moco_v2 model\n",
    "# moco_model = Moco_v2.load_from_checkpoint(checkpoint_path='/mnt/ceph/users/flanusse/resnet50.ckpt')\n",
    "# backbone = moco_model.encoder_q\n",
    "# moco_model = OutputExtractor(backbone).to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/234996 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'image'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/mnt/sw/nix/store/b4q5asj8flwlgmaijgj1r6wbmnls5x8k-python-3.9.15-view/lib/python3.9/site-packages/astropy/table/row.py:51\u001b[0m, in \u001b[0;36mRow.__getitem__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     48\u001b[0m     \u001b[39m# Try the most common use case of accessing a single column in the Row.\u001b[39;00m\n\u001b[1;32m     49\u001b[0m     \u001b[39m# Bypass the TableColumns __getitem__ since that does more testing\u001b[39;00m\n\u001b[1;32m     50\u001b[0m     \u001b[39m# and allows a list of tuple or str, which is not the right thing here.\u001b[39;00m\n\u001b[0;32m---> 51\u001b[0m     out \u001b[39m=\u001b[39m OrderedDict\u001b[39m.\u001b[39;49m\u001b[39m__getitem__\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_table\u001b[39m.\u001b[39;49mcolumns, item)[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_index]\n\u001b[1;32m     52\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyError\u001b[39;00m, \u001b[39mTypeError\u001b[39;00m):\n",
      "\u001b[0;31mKeyError\u001b[0m: 'image'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/mnt/home/lparker/Documents/AstroFoundationModel/AstroBaselines/morphology_classification/develop.ipynb Cell 11\u001b[0m in \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bpolymathiclin030/mnt/home/lparker/Documents/AstroFoundationModel/AstroBaselines/morphology_classification/develop.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m total_batches \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(classifications) \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m batch_size\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bpolymathiclin030/mnt/home/lparker/Documents/AstroFoundationModel/AstroBaselines/morphology_classification/develop.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mfor\u001b[39;00m k, entry \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(tqdm(classifications)):\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bpolymathiclin030/mnt/home/lparker/Documents/AstroFoundationModel/AstroBaselines/morphology_classification/develop.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m     image \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(entry[\u001b[39m'\u001b[39m\u001b[39mimage\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bpolymathiclin030/mnt/home/lparker/Documents/AstroFoundationModel/AstroBaselines/morphology_classification/develop.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m     batch\u001b[39m.\u001b[39mappend(image)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bpolymathiclin030/mnt/home/lparker/Documents/AstroFoundationModel/AstroBaselines/morphology_classification/develop.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(batch) \u001b[39m==\u001b[39m batch_size:\n",
      "File \u001b[0;32m/mnt/sw/nix/store/b4q5asj8flwlgmaijgj1r6wbmnls5x8k-python-3.9.15-view/lib/python3.9/site-packages/astropy/table/row.py:58\u001b[0m, in \u001b[0;36mRow.__getitem__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m     55\u001b[0m         out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_table\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m(cols, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_index]\n\u001b[1;32m     56\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     57\u001b[0m         \u001b[39m# This is only to raise an exception\u001b[39;00m\n\u001b[0;32m---> 58\u001b[0m         out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_table\u001b[39m.\u001b[39;49mcolumns[item][\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_index]\n\u001b[1;32m     59\u001b[0m \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m/mnt/sw/nix/store/b4q5asj8flwlgmaijgj1r6wbmnls5x8k-python-3.9.15-view/lib/python3.9/site-packages/astropy/table/table.py:246\u001b[0m, in \u001b[0;36mTableColumns.__getitem__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Get items from a TableColumns object.\u001b[39;00m\n\u001b[1;32m    237\u001b[0m \u001b[39m::\u001b[39;00m\n\u001b[1;32m    238\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[39m  tc[1:3] # <TableColumns names=('b', 'c')>\u001b[39;00m\n\u001b[1;32m    244\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    245\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(item, \u001b[39mstr\u001b[39m):\n\u001b[0;32m--> 246\u001b[0m     \u001b[39mreturn\u001b[39;00m OrderedDict\u001b[39m.\u001b[39;49m\u001b[39m__getitem__\u001b[39;49m(\u001b[39mself\u001b[39;49m, item)\n\u001b[1;32m    247\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(item, (\u001b[39mint\u001b[39m, np\u001b[39m.\u001b[39minteger)):\n\u001b[1;32m    248\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mlist\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvalues())[item]\n",
      "\u001b[0;31mKeyError\u001b[0m: 'image'"
     ]
    }
   ],
   "source": [
    "astroclip.cuda()\n",
    "DINO.cuda()\n",
    "#moco_model.cuda()\n",
    "CLIP_embeddings = []\n",
    "DINO_embeddings = []\n",
    "stein_embeddings = []\n",
    "\n",
    "batch, batch_size = [], 512\n",
    "total_batches = len(classifications) // batch_size\n",
    "\n",
    "for k, entry in enumerate(tqdm(classifications)):\n",
    "    image = torch.tensor(entry['image'])\n",
    "    batch.append(image)\n",
    "\n",
    "    if len(batch) == batch_size:\n",
    "        batch = torch.stack(batch)\n",
    "\n",
    "        #with torch.no_grad():\n",
    "            #stein_embeddings.append(moco_model(batch.to(torch.float32).cuda()).detach().cpu().numpy())\n",
    "\n",
    "        batch = np.array(to_rgb(batch.permute(0, 2, 3, 1))*255).astype('uint8').transpose(0, 2, 3, 1)\n",
    "        batch = torch.stack([img_transforms(im.fromarray(batch[i])) for i in range(batch.shape[0])])\n",
    "\n",
    "        with torch.no_grad():\n",
    "            CLIP_embeddings.append(astroclip(batch.cuda(), image=True).detach().cpu().numpy())\n",
    "            DINO_embeddings.append(DINO.forward(batch.cuda()).detach().cpu().numpy())\n",
    "        batch = []\n",
    "\n",
    "    # do last batch\n",
    "    if k == len(classifications) - 1:\n",
    "        batch = torch.stack(batch)\n",
    "\n",
    "        # with torch.no_grad():\n",
    "        #     stein_embeddings.append(moco_model(batch.to(torch.float32).cuda()).detach().cpu().numpy())\n",
    "\n",
    "        batch = np.array(to_rgb(batch.permute(0, 2, 3, 1))*255).astype('uint8').transpose(0, 2, 3, 1)\n",
    "        batch = torch.stack([img_transforms(im.fromarray(batch[i])) for i in range(batch.shape[0])])\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            CLIP_embeddings.append(astroclip(batch.cuda(), image=True).detach().cpu().numpy())\n",
    "            DINO_embeddings.append(DINO.forward(batch.cuda()).detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, TensorDataset, WeightedRandomSampler\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes, hidden_dim, dropout_rate):\n",
    "        super().__init__()\n",
    "\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, num_classes)\n",
    "        )\n",
    "\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layers(x)\n",
    "        x = self.softmax(x)\n",
    "        return x.squeeze()\n",
    "\n",
    "def train_eval_MLP(X_train, X_test, y_train, y_test, embed_dim, num_classes, MLP_dim=128, lr=1e-3, epochs=25, dropout=0.2): \n",
    "    # Split the dataset into training and validation sets\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=42)\n",
    "\n",
    "    train_dataset = TensorDataset(X_train, y_train)\n",
    "    val_dataset = TensorDataset(X_val, y_val)\n",
    "\n",
    "    # Create a DataLoader\n",
    "    samples_weight = y_train.max(dim=1).values  # Taking max fraction as the weight\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=256, sampler=WeightedRandomSampler(samples_weight, len(samples_weight)))\n",
    "    val_loader = DataLoader(val_dataset, batch_size=256, shuffle=False)\n",
    "\n",
    "    mlp = MLP(embed_dim, num_classes, MLP_dim, dropout)\n",
    "    criterion = nn.BCEWithLogitsLoss()  # Suitable for multi-label classification\n",
    "    optimizer = optim.Adam(mlp.parameters(), lr=lr)\n",
    "\n",
    "    # Training loop\n",
    "    best_val_loss = float('inf')\n",
    "    best_metrics = None\n",
    "\n",
    "    for epoch in range(epochs):  # Define your number of epochs\n",
    "        mlp.train()\n",
    "        train_loss = 0\n",
    "        for data, target in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            output = mlp(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        train_loss /= len(train_loader)\n",
    "\n",
    "        # Validation loop\n",
    "        mlp.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for data, target in val_loader:\n",
    "                output = mlp(data)\n",
    "                loss = criterion(output, target)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "        val_loss /= len(val_loader)\n",
    "        \n",
    "        # Report every 25 epochs\n",
    "        #if epoch % 25 == 0:\n",
    "        #    print(f'Epoch {epoch}: Train Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}')\n",
    "\n",
    "        # Save best model based on validation loss\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_model = mlp.state_dict()\n",
    "            \n",
    "    mlp.load_state_dict(best_model)\n",
    "    y_pred = mlp(X_test).detach()\n",
    "    \n",
    "    y_pred = (y_pred == torch.max(y_pred, dim=1, keepdim=True).values).int()\n",
    "    y_true = (y_test == torch.max(y_test, dim=1, keepdim=True).values).int()\n",
    "    \n",
    "    accuracy = accuracy_score(y_true.numpy(), y_pred.numpy())\n",
    "    f1_score = precision_recall_fscore_support(y_true.numpy(), y_pred.numpy(), average='weighted', zero_division=0)[2]\n",
    "    return {'Accuracy': accuracy, 'F1 Score': f1_score}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_CLIP = torch.tensor(np.concatenate(CLIP_embeddings))\n",
    "X_DINO = torch.tensor(np.concatenate(DINO_embeddings))\n",
    "X_Stein = torch.tensor(np.concatenate(stein_embeddings))\n",
    "\n",
    "X = {}\n",
    "\n",
    "X['CLIP'] = X_CLIP\n",
    "X['DINO'] = X_DINO\n",
    "X['Stein'] = X_Stein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = '/mnt/home/lparker/ceph/gz5_south/'\n",
    "\n",
    "X = {}\n",
    "\n",
    "X['CLIP'] = torch.load(dir + 'X_CLIP.pt')\n",
    "X['DINO'] = torch.load(dir + 'X_DINO.pt')\n",
    "X['Stein'] = torch.load(dir + 'X_Stein.pt')\n",
    "\n",
    "classifications = Table.read(dir + 'classifications.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle all X and classifications in the same way\n",
    "np.random.seed(42)\n",
    "\n",
    "shuffled_indices = np.random.permutation(len(classifications))\n",
    "\n",
    "for key in X.keys():\n",
    "    X[key] = X[key][shuffled_indices]\n",
    "\n",
    "classifications = classifications[shuffled_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select first 80% for train and last 20% for test\n",
    "train_indices = int(0.8 * len(classifications))\n",
    "\n",
    "X_train = {}\n",
    "X_test = {}\n",
    "\n",
    "for key in X.keys():\n",
    "    X_train[key] = X[key][:train_indices]\n",
    "    X_test[key] = X[key][train_indices:]\n",
    "\n",
    "classifications_train, classifications_test = classifications[:train_indices], classifications[train_indices:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = {}\n",
    "names = ['smooth', 'disk-edge-on', 'spiral-arms', 'bar', 'bulge-size', 'how-rounded', 'edge-on-bulge', 'spiral-winding', 'spiral-arm-count', 'merging']\n",
    "for name in names:\n",
    "    local_dict = {}\n",
    "    local_dict['debiased'] = [key for key in classifications.colnames if name in key and 'debiased' in key]\n",
    "    local_dict['counts'] = [key for key in classifications.colnames if name in key and 'total-votes' in key]\n",
    "    keys[name] = local_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: smooth, Classes: ['smooth-or-featured_smooth_debiased', 'smooth-or-featured_featured-or-disk_debiased', 'smooth-or-featured_artifact_debiased']\n",
      "Number of classes: 3, Number of samples: 10074\n",
      "CLIP - Accuracy: 0.8367, F1 Score: 0.8215\n",
      "DINO - Accuracy: 0.8331, F1 Score: 0.8119\n",
      "Stein - Accuracy: 0.7819, F1 Score: 0.6865\n",
      "\n",
      "Question: disk-edge-on, Classes: ['disk-edge-on_yes_debiased', 'disk-edge-on_no_debiased']\n",
      "Number of classes: 2, Number of samples: 1297\n",
      "CLIP - Accuracy: 0.9522, F1 Score: 0.9506\n",
      "DINO - Accuracy: 0.9584, F1 Score: 0.9586\n",
      "Stein - Accuracy: 0.8774, F1 Score: 0.8201\n",
      "\n",
      "Question: spiral-arms, Classes: ['has-spiral-arms_yes_debiased', 'has-spiral-arms_no_debiased']\n",
      "Number of classes: 2, Number of samples: 972\n",
      "CLIP - Accuracy: 0.9805, F1 Score: 0.9708\n",
      "DINO - Accuracy: 0.9805, F1 Score: 0.9708\n",
      "Stein - Accuracy: 0.9805, F1 Score: 0.9708\n",
      "\n",
      "Question: bar, Classes: ['bar_strong_debiased', 'bar_weak_debiased', 'bar_no_debiased']\n",
      "Number of classes: 3, Number of samples: 972\n",
      "CLIP - Accuracy: 0.5535, F1 Score: 0.5250\n",
      "DINO - Accuracy: 0.5772, F1 Score: 0.5467\n",
      "Stein - Accuracy: 0.5607, F1 Score: 0.4779\n",
      "\n",
      "Question: bulge-size, Classes: ['bulge-size_dominant_debiased', 'bulge-size_large_debiased', 'bulge-size_moderate_debiased', 'bulge-size_small_debiased', 'bulge-size_none_debiased']\n",
      "Number of classes: 5, Number of samples: 972\n",
      "CLIP - Accuracy: 0.7963, F1 Score: 0.7866\n",
      "DINO - Accuracy: 0.7984, F1 Score: 0.7888\n",
      "Stein - Accuracy: 0.6903, F1 Score: 0.5639\n",
      "\n",
      "Question: how-rounded, Classes: ['how-rounded_round_debiased', 'how-rounded_in-between_debiased', 'how-rounded_cigar-shaped_debiased']\n",
      "Number of classes: 3, Number of samples: 1389\n",
      "CLIP - Accuracy: 0.6897, F1 Score: 0.6926\n",
      "DINO - Accuracy: 0.8265, F1 Score: 0.8283\n",
      "Stein - Accuracy: 0.5212, F1 Score: 0.4707\n",
      "\n",
      "Question: edge-on-bulge, Classes: ['edge-on-bulge_boxy_debiased', 'edge-on-bulge_none_debiased', 'edge-on-bulge_rounded_debiased']\n",
      "Number of classes: 3, Number of samples: 121\n",
      "CLIP - Accuracy: 0.8347, F1 Score: 0.8041\n",
      "DINO - Accuracy: 0.8264, F1 Score: 0.7872\n",
      "Stein - Accuracy: 0.7686, F1 Score: 0.6680\n",
      "\n",
      "Question: spiral-winding, Classes: ['spiral-winding_tight_debiased', 'spiral-winding_medium_debiased', 'spiral-winding_loose_debiased']\n",
      "Number of classes: 3, Number of samples: 711\n",
      "CLIP - Accuracy: 0.7665, F1 Score: 0.6969\n",
      "DINO - Accuracy: 0.7707, F1 Score: 0.6710\n",
      "Stein - Accuracy: 0.7707, F1 Score: 0.6710\n",
      "\n",
      "Question: spiral-arm-count, Classes: ['spiral-arm-count_1_debiased', 'spiral-arm-count_2_debiased', 'spiral-arm-count_3_debiased', 'spiral-arm-count_4_debiased', 'spiral-arm-count_more-than-4_debiased', 'spiral-arm-count_cant-tell_debiased']\n",
      "Number of classes: 6, Number of samples: 711\n",
      "CLIP - Accuracy: 0.5837, F1 Score: 0.4353\n",
      "DINO - Accuracy: 0.5851, F1 Score: 0.4352\n",
      "Stein - Accuracy: 0.5851, F1 Score: 0.4352\n",
      "\n",
      "Question: merging, Classes: ['merging_none_debiased', 'merging_minor-disturbance_debiased', 'merging_major-disturbance_debiased', 'merging_merger_debiased']\n",
      "Number of classes: 4, Number of samples: 7214\n",
      "CLIP - Accuracy: 0.8198, F1 Score: 0.7408\n",
      "DINO - Accuracy: 0.8380, F1 Score: 0.7820\n",
      "Stein - Accuracy: 0.8210, F1 Score: 0.7350\n",
      "\n"
     ]
    }
   ],
   "source": [
    "total_counts_train = classifications_train[keys['smooth']['counts']].to_pandas().values\n",
    "\n",
    "outputs = {'CLIP': {}, 'DINO': {}, 'Stein': {}}\n",
    "\n",
    "for name in names:\n",
    "    question, num_classes = name, len(keys[name]['debiased'])\n",
    "\n",
    "    counts_train = classifications_train[keys[name]['counts']].to_pandas().values\n",
    "    pct_answered = np.array(counts_train/total_counts_train)\n",
    "    above50 = np.where(pct_answered > .5)[0]\n",
    "\n",
    "    y_train = torch.tensor(classifications_train[keys[name]['debiased']].to_pandas().values)[above50]\n",
    "    train_mask = torch.isnan(y_train).any(axis=1)\n",
    "    y_train = y_train[~train_mask]\n",
    "     \n",
    "    counts_test = np.array(classifications_test[keys[name]['counts']].to_pandas().values)\n",
    "    above35 = np.where(counts_test > 35)[0]\n",
    "\n",
    "    y_test = torch.tensor(classifications_test[keys[name]['debiased']].to_pandas().values)[above35]\n",
    "    test_mask = torch.isnan(y_test).any(axis=1)\n",
    "    y_test = y_test[~test_mask]\n",
    "\n",
    "    categories = keys[name]['debiased']\n",
    "    print(f'Question: {question}, Classes: {categories}')\n",
    "    print(f'Number of classes: {num_classes}, Number of samples: {len(y_test)}')\n",
    "\n",
    "    for model in X.keys():\n",
    "        X_train_local = X_train[model][above50][~train_mask]\n",
    "        X_test_local = X_test[model][above35][~test_mask]\n",
    "\n",
    "        outputs[model][name] = train_eval_MLP(X_train_local, X_test_local,  y_train, y_test, X_train_local.shape[1], num_classes=num_classes, MLP_dim=128, epochs=25, dropout=0.2)\n",
    "        print(f'{model} - Accuracy: {outputs[model][name][\"Accuracy\"]:.4f}, F1 Score: {outputs[model][name][\"F1 Score\"]:.4f}')\n",
    "\n",
    "    print('')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import pi\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_radar(outputs, metric, file_path, title='Galaxy Property Estimation', fontsize=25):\n",
    "    questions = {}\n",
    "    for key in outputs.keys():\n",
    "        questions[key] = [outputs[key][question][metric] for question in outputs[key].keys()]\n",
    "\n",
    "    # Create radar chart\n",
    "    angles = np.linspace(0, 2 * pi, len(questions[key]), endpoint=False).tolist()\n",
    "    angles += angles[:1]  # complete the loop\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(12, 12), subplot_kw=dict(polar=True))\n",
    "\n",
    "    colors = ['red', 'red', 'black', 'blue']\n",
    "    styles = ['solid', 'dashed', 'solid', 'solid']\n",
    "\n",
    "    # Plot each array on the radar chart\n",
    "    for key in questions.keys():\n",
    "        #if key == 'ZooBot': continue\n",
    "        stats = [questions[key][i] for i in range(len(questions[key]))]\n",
    "        stats += stats[:1]  \n",
    "        ax.plot(angles, stats, label=key, linewidth=2, linestyle=styles.pop(0), color=colors.pop(0))\n",
    "\n",
    "    labels = outputs[key].keys()\n",
    "\n",
    "    # capitalize labels\n",
    "    labels = [label.capitalize() for label in labels]\n",
    "\n",
    "    # Add labels with specific fontsize\n",
    "    ax.set_theta_offset(pi / 2)\n",
    "    ax.set_theta_direction(-1)\n",
    "\n",
    "    # Change r label to fontsize\n",
    "    ax.tick_params(axis='y', labelsize=fontsize)\n",
    "\n",
    "    ax.set_xticks(angles[:-1], labels, fontsize=fontsize, color='black')\n",
    "\n",
    "    # make not overlap with plot\n",
    "    #ax.set_xticklabels(labels, fontsize=fontsize)\n",
    "\n",
    "    # make theta labels not overlap with plot    \n",
    "    ax.set_ylim(0, 1.)\n",
    "\n",
    "    # Add legend and title with specific fontsize\n",
    "    legend = plt.legend(loc='upper right', bbox_to_anchor=(1.1, 1.1))\n",
    "    plt.setp(legend.get_texts(), fontsize=fontsize)  # Explicitly set fontsize for legend\n",
    "\n",
    "    plt.savefig(file_path)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs['ZooBot'] = {\n",
    "    'smooth': {'Accuracy': 0.94, 'F1 Score': 0.94},\n",
    "    'disk-edge-on': {'Accuracy': 0.99, 'F1 Score': 0.99},\n",
    "    'spiral-arms': {'Accuracy': 0.93, 'F1 Score': 0.94},\n",
    "    'bar': {'Accuracy': 0.82, 'F1 Score': 0.81},\n",
    "    'bulge-size': {'Accuracy': 0.84, 'F1 Score': 0.84},\n",
    "    'how-rounded': {'Accuracy': 0.93, 'F1 Score': 0.93},\n",
    "    'edge-on-bulge': {'Accuracy': 0.91, 'F1 Score': 0.90},\n",
    "    'spiral-winding': {'Accuracy': 0.78, 'F1 Score': 0.79},\n",
    "    'spiral-arm-count': {'Accuracy': 0.77, 'F1 Score': 0.76},\n",
    "    'merging': {'Accuracy': 0.88, 'F1 Score': 0.85}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_radar(outputs, 'Accuracy', title='Galaxy Property Estimation', file_path = 'accuracy.png', fontsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_radar(outputs, 'F1 Score', title='Galaxy Property Estimation', file_path = 'f1_score.png', fontsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "acc, f1 = {}, {}\n",
    "for key in outputs.keys():\n",
    "    acc[key] = [outputs[key][question]['Accuracy'] for question in outputs[key].keys()]\n",
    "    f1[key] = [outputs[key][question]['F1 Score'] for question in outputs[key].keys()]\n",
    "\n",
    "acc = pd.DataFrame(acc, index=outputs[key].keys())\n",
    "f1 = pd.DataFrame(f1, index=outputs[key].keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CLIP</th>\n",
       "      <th>DINO</th>\n",
       "      <th>Stein</th>\n",
       "      <th>ZooBot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>smooth</th>\n",
       "      <td>0.836708</td>\n",
       "      <td>0.833135</td>\n",
       "      <td>0.781914</td>\n",
       "      <td>0.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>disk-edge-on</th>\n",
       "      <td>0.952197</td>\n",
       "      <td>0.958365</td>\n",
       "      <td>0.877409</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spiral-arms</th>\n",
       "      <td>0.980453</td>\n",
       "      <td>0.980453</td>\n",
       "      <td>0.980453</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bar</th>\n",
       "      <td>0.553498</td>\n",
       "      <td>0.577160</td>\n",
       "      <td>0.560700</td>\n",
       "      <td>0.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bulge-size</th>\n",
       "      <td>0.796296</td>\n",
       "      <td>0.798354</td>\n",
       "      <td>0.690329</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>how-rounded</th>\n",
       "      <td>0.689705</td>\n",
       "      <td>0.826494</td>\n",
       "      <td>0.521238</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>edge-on-bulge</th>\n",
       "      <td>0.834711</td>\n",
       "      <td>0.826446</td>\n",
       "      <td>0.768595</td>\n",
       "      <td>0.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spiral-winding</th>\n",
       "      <td>0.766526</td>\n",
       "      <td>0.770745</td>\n",
       "      <td>0.770745</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spiral-arm-count</th>\n",
       "      <td>0.583685</td>\n",
       "      <td>0.585091</td>\n",
       "      <td>0.585091</td>\n",
       "      <td>0.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>merging</th>\n",
       "      <td>0.819795</td>\n",
       "      <td>0.837954</td>\n",
       "      <td>0.821042</td>\n",
       "      <td>0.88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      CLIP      DINO     Stein  ZooBot\n",
       "smooth            0.836708  0.833135  0.781914    0.94\n",
       "disk-edge-on      0.952197  0.958365  0.877409    0.99\n",
       "spiral-arms       0.980453  0.980453  0.980453    0.93\n",
       "bar               0.553498  0.577160  0.560700    0.82\n",
       "bulge-size        0.796296  0.798354  0.690329    0.84\n",
       "how-rounded       0.689705  0.826494  0.521238    0.93\n",
       "edge-on-bulge     0.834711  0.826446  0.768595    0.91\n",
       "spiral-winding    0.766526  0.770745  0.770745    0.78\n",
       "spiral-arm-count  0.583685  0.585091  0.585091    0.77\n",
       "merging           0.819795  0.837954  0.821042    0.88"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save acc and f1\n",
    "acc.to_csv('accuracy.csv')\n",
    "f1.to_csv('f1_score.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CLIP      0.781357\n",
       "DINO      0.799420\n",
       "Stein     0.735752\n",
       "ZooBot    0.879000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CLIP</th>\n",
       "      <th>DINO</th>\n",
       "      <th>Stein</th>\n",
       "      <th>ZooBot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>smooth</th>\n",
       "      <td>0.821478</td>\n",
       "      <td>0.811942</td>\n",
       "      <td>0.686488</td>\n",
       "      <td>0.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>disk-edge-on</th>\n",
       "      <td>0.950650</td>\n",
       "      <td>0.958587</td>\n",
       "      <td>0.820117</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spiral-arms</th>\n",
       "      <td>0.970775</td>\n",
       "      <td>0.970775</td>\n",
       "      <td>0.970775</td>\n",
       "      <td>0.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bar</th>\n",
       "      <td>0.525032</td>\n",
       "      <td>0.546726</td>\n",
       "      <td>0.477928</td>\n",
       "      <td>0.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bulge-size</th>\n",
       "      <td>0.786643</td>\n",
       "      <td>0.788754</td>\n",
       "      <td>0.563860</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>how-rounded</th>\n",
       "      <td>0.692555</td>\n",
       "      <td>0.828264</td>\n",
       "      <td>0.470709</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>edge-on-bulge</th>\n",
       "      <td>0.804079</td>\n",
       "      <td>0.787162</td>\n",
       "      <td>0.668031</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spiral-winding</th>\n",
       "      <td>0.696921</td>\n",
       "      <td>0.670959</td>\n",
       "      <td>0.670959</td>\n",
       "      <td>0.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spiral-arm-count</th>\n",
       "      <td>0.435310</td>\n",
       "      <td>0.435192</td>\n",
       "      <td>0.435192</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>merging</th>\n",
       "      <td>0.740755</td>\n",
       "      <td>0.782008</td>\n",
       "      <td>0.734958</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      CLIP      DINO     Stein  ZooBot\n",
       "smooth            0.821478  0.811942  0.686488    0.94\n",
       "disk-edge-on      0.950650  0.958587  0.820117    0.99\n",
       "spiral-arms       0.970775  0.970775  0.970775    0.94\n",
       "bar               0.525032  0.546726  0.477928    0.81\n",
       "bulge-size        0.786643  0.788754  0.563860    0.84\n",
       "how-rounded       0.692555  0.828264  0.470709    0.93\n",
       "edge-on-bulge     0.804079  0.787162  0.668031    0.90\n",
       "spiral-winding    0.696921  0.670959  0.670959    0.79\n",
       "spiral-arm-count  0.435310  0.435192  0.435192    0.76\n",
       "merging           0.740755  0.782008  0.734958    0.85"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CLIP      0.742420\n",
       "DINO      0.758037\n",
       "Stein     0.649902\n",
       "ZooBot    0.875000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# average over rows\n",
    "f1.mean(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GZ2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP\n",
      "Epoch 0: Train Loss: 0.6665, Validation Loss: 0.6555\n",
      "Epoch 25: Train Loss: 0.6495, Validation Loss: 0.6510\n",
      "Epoch 50: Train Loss: 0.6482, Validation Loss: 0.6512\n",
      "Epoch 75: Train Loss: 0.6475, Validation Loss: 0.6516\n",
      "W20240311 12:28:13 3227326 py.warnings warnings.py:109] /mnt/sw/nix/store/b4q5asj8flwlgmaijgj1r6wbmnls5x8k-python-3.9.15-view/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      "Accuracy: 0.8630, F1 Score: 0.8651\n",
      "DINO\n",
      "Epoch 0: Train Loss: 0.6610, Validation Loss: 0.6500\n",
      "Epoch 25: Train Loss: 0.6455, Validation Loss: 0.6458\n",
      "Epoch 50: Train Loss: 0.6445, Validation Loss: 0.6464\n",
      "Epoch 75: Train Loss: 0.6434, Validation Loss: 0.6467\n",
      "W20240311 12:29:00 3227326 py.warnings warnings.py:109] /mnt/sw/nix/store/b4q5asj8flwlgmaijgj1r6wbmnls5x8k-python-3.9.15-view/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      "Accuracy: 0.8948, F1 Score: 0.8973\n",
      "Stein\n",
      "Epoch 0: Train Loss: 0.7161, Validation Loss: 0.6893\n",
      "Epoch 25: Train Loss: 0.6674, Validation Loss: 0.6670\n",
      "Epoch 50: Train Loss: 0.6656, Validation Loss: 0.6651\n",
      "Epoch 75: Train Loss: 0.6643, Validation Loss: 0.6638\n",
      "W20240311 12:29:38 3227326 py.warnings warnings.py:109] /mnt/sw/nix/store/b4q5asj8flwlgmaijgj1r6wbmnls5x8k-python-3.9.15-view/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      "Accuracy: 0.8202, F1 Score: 0.8119\n"
     ]
    }
   ],
   "source": [
    "# Get Results for Smooth Question\n",
    "\n",
    "question, num_classes = 'Smooth', 3\n",
    "\n",
    "smooth = torch.tensor(classifications['t01_smooth_or_features_a01_smooth_fraction', \n",
    "                        't01_smooth_or_features_a02_features_or_disk_fraction', \n",
    "                        't01_smooth_or_features_a03_star_or_artifact_fraction'])\n",
    "\n",
    "print('CLIP')\n",
    "outputs['CLIP'][question] = train_eval_MLP(X_CLIP, smooth, embed_dim=512, num_classes=num_classes, MLP_dim=32, epochs=100)\n",
    "\n",
    "print('DINO')\n",
    "outputs['DINO'][question] = train_eval_MLP(X_DINO, smooth, embed_dim=1024, num_classes=num_classes, MLP_dim=32, epochs=100)\n",
    "\n",
    "print('Stein')\n",
    "outputs['Stein'][question] = train_eval_MLP(X_Stein, smooth, embed_dim=128, num_classes=num_classes, MLP_dim=32, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP\n",
      "Epoch 0: Train Loss: 0.5917, Validation Loss: 0.5592\n",
      "Epoch 25: Train Loss: 0.5413, Validation Loss: 0.5419\n",
      "Epoch 50: Train Loss: 0.5415, Validation Loss: 0.5436\n",
      "Epoch 75: Train Loss: 0.5383, Validation Loss: 0.5403\n",
      "Accuracy: 0.9480, F1 Score: 0.9458\n",
      "DINO\n",
      "Epoch 0: Train Loss: 0.5943, Validation Loss: 0.5665\n",
      "Epoch 25: Train Loss: 0.5367, Validation Loss: 0.5387\n",
      "Epoch 50: Train Loss: 0.5348, Validation Loss: 0.5383\n",
      "Epoch 75: Train Loss: 0.5344, Validation Loss: 0.5391\n",
      "Accuracy: 0.9657, F1 Score: 0.9657\n",
      "Stein\n",
      "Epoch 0: Train Loss: 0.7011, Validation Loss: 0.6853\n",
      "Epoch 25: Train Loss: 0.5876, Validation Loss: 0.5833\n",
      "Epoch 50: Train Loss: 0.5875, Validation Loss: 0.5832\n",
      "Epoch 75: Train Loss: 0.5875, Validation Loss: 0.5832\n",
      "W20240311 12:30:09 3227326 py.warnings warnings.py:109] /mnt/sw/nix/store/b4q5asj8flwlgmaijgj1r6wbmnls5x8k-python-3.9.15-view/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      "Accuracy: 0.8574, F1 Score: 0.7918\n"
     ]
    }
   ],
   "source": [
    "# Get Results for Edge On Question\n",
    "\n",
    "question, num_classes = 'Edge On', 2\n",
    "\n",
    "counts = classifications['t02_edgeon_a04_yes_count'] + classifications['t02_edgeon_a05_no_count']\n",
    "total = classifications['total_classifications']\n",
    "pct_answered = np.array(counts/total)\n",
    "above50 = np.where(pct_answered > .5)[0]\n",
    "\n",
    "y = classifications['t02_edgeon_a04_yes_fraction', 't02_edgeon_a05_no_fraction']\n",
    "y = torch.tensor(y[above50])\n",
    "\n",
    "print('CLIP')\n",
    "outputs['CLIP'][question] = train_eval_MLP(X_CLIP[above50], y, embed_dim=512, num_classes=num_classes, MLP_dim=32, epochs=100)\n",
    "\n",
    "print('DINO')\n",
    "outputs['DINO'][question] = train_eval_MLP(X_DINO[above50], y, embed_dim=1024, num_classes=num_classes, MLP_dim=32, epochs=100)\n",
    "\n",
    "print('Stein')\n",
    "outputs['Stein'][question] = train_eval_MLP(X_Stein[above50], y, embed_dim=128, num_classes=num_classes, MLP_dim=32, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP\n",
      "Epoch 0: Train Loss: 0.6779, Validation Loss: 0.6714\n",
      "Epoch 25: Train Loss: 0.6509, Validation Loss: 0.6638\n",
      "Epoch 50: Train Loss: 0.6444, Validation Loss: 0.6630\n",
      "Epoch 75: Train Loss: 0.6355, Validation Loss: 0.6624\n",
      "Accuracy: 0.7312, F1 Score: 0.7242\n",
      "DINO\n",
      "Epoch 0: Train Loss: 0.6790, Validation Loss: 0.6700\n",
      "Epoch 25: Train Loss: 0.6418, Validation Loss: 0.6543\n",
      "Epoch 50: Train Loss: 0.6346, Validation Loss: 0.6520\n",
      "Epoch 75: Train Loss: 0.6322, Validation Loss: 0.6553\n",
      "Accuracy: 0.7657, F1 Score: 0.7506\n",
      "Stein\n",
      "Epoch 0: Train Loss: 0.7124, Validation Loss: 0.7058\n",
      "Epoch 25: Train Loss: 0.6724, Validation Loss: 0.6727\n",
      "Epoch 50: Train Loss: 0.6723, Validation Loss: 0.6726\n",
      "Epoch 75: Train Loss: 0.6723, Validation Loss: 0.6726\n",
      "W20240311 12:31:11 3227326 py.warnings warnings.py:109] /mnt/sw/nix/store/b4q5asj8flwlgmaijgj1r6wbmnls5x8k-python-3.9.15-view/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      "Accuracy: 0.7257, F1 Score: 0.6205\n"
     ]
    }
   ],
   "source": [
    "# Get Results for Bar Question\n",
    "\n",
    "question, num_classes = 'Bar', 2\n",
    "\n",
    "counts = classifications['t03_bar_a06_bar_count'] + classifications['t03_bar_a07_no_bar_count']\n",
    "total = classifications['total_classifications']\n",
    "pct_answered = np.array(counts/total)\n",
    "above50 = np.where(pct_answered > .5)[0]\n",
    "\n",
    "y = classifications['t03_bar_a06_bar_fraction', 't03_bar_a07_no_bar_fraction']\n",
    "y = torch.tensor(y[above50])\n",
    "\n",
    "print('CLIP')\n",
    "outputs['CLIP'][question] = train_eval_MLP(X_CLIP[above50], y, embed_dim=512, num_classes=num_classes, MLP_dim=32, epochs=100)\n",
    "\n",
    "print('DINO')\n",
    "outputs['DINO'][question] = train_eval_MLP(X_DINO[above50], y, embed_dim=1024, num_classes=num_classes, MLP_dim=32, epochs=100)\n",
    "\n",
    "print('Stein')\n",
    "outputs['Stein'][question] = train_eval_MLP(X_Stein[above50], y, embed_dim=128, num_classes=num_classes, MLP_dim=32, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP\n",
      "Epoch 0: Train Loss: 0.6158, Validation Loss: 0.5998\n",
      "Epoch 25: Train Loss: 0.5978, Validation Loss: 0.5987\n",
      "Epoch 50: Train Loss: 0.5957, Validation Loss: 0.6003\n",
      "Epoch 75: Train Loss: 0.5943, Validation Loss: 0.6003\n",
      "Accuracy: 0.8825, F1 Score: 0.8494\n",
      "DINO\n",
      "Epoch 0: Train Loss: 0.6211, Validation Loss: 0.5999\n",
      "Epoch 25: Train Loss: 0.5978, Validation Loss: 0.5989\n",
      "Epoch 50: Train Loss: 0.5957, Validation Loss: 0.5993\n",
      "Epoch 75: Train Loss: 0.5951, Validation Loss: 0.6005\n",
      "Accuracy: 0.8788, F1 Score: 0.8483\n",
      "Stein\n",
      "Epoch 0: Train Loss: 0.6963, Validation Loss: 0.6791\n",
      "Epoch 25: Train Loss: 0.6019, Validation Loss: 0.5993\n",
      "Epoch 50: Train Loss: 0.6018, Validation Loss: 0.5992\n",
      "Epoch 75: Train Loss: 0.6017, Validation Loss: 0.5992\n",
      "W20240311 12:31:35 3227326 py.warnings warnings.py:109] /mnt/sw/nix/store/b4q5asj8flwlgmaijgj1r6wbmnls5x8k-python-3.9.15-view/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      "Accuracy: 0.8801, F1 Score: 0.8266\n"
     ]
    }
   ],
   "source": [
    "# Get Results for Spiral Question\n",
    "\n",
    "question, num_classes = 'Spiral Count', 2\n",
    "\n",
    "counts = classifications['t04_spiral_a08_spiral_count'] + classifications['t04_spiral_a09_no_spiral_count']\n",
    "total = classifications['total_classifications']\n",
    "pct_answered = np.array(counts/total)\n",
    "above50 = np.where(pct_answered > .5)[0]\n",
    "\n",
    "y = classifications['t04_spiral_a08_spiral_fraction', 't04_spiral_a09_no_spiral_fraction']\n",
    "y = torch.tensor(y[above50])\n",
    "\n",
    "print('CLIP')\n",
    "outputs['CLIP'][question] = train_eval_MLP(X_CLIP[above50], y, embed_dim=512, num_classes=num_classes, MLP_dim=32, epochs=100)\n",
    "\n",
    "print('DINO')\n",
    "outputs['DINO'][question] = train_eval_MLP(X_DINO[above50], y, embed_dim=1024, num_classes=num_classes, MLP_dim=32, epochs=100)\n",
    "\n",
    "print('Stein')\n",
    "outputs['Stein'][question] = train_eval_MLP(X_Stein[above50], y, embed_dim=128, num_classes=num_classes, MLP_dim=32, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP\n",
      "Epoch 0: Train Loss: 0.7200, Validation Loss: 0.7044\n",
      "Epoch 25: Train Loss: 0.6993, Validation Loss: 0.7019\n",
      "Epoch 50: Train Loss: 0.6980, Validation Loss: 0.7021\n",
      "Epoch 75: Train Loss: 0.6970, Validation Loss: 0.7025\n",
      "W20240311 12:31:57 3227326 py.warnings warnings.py:109] /mnt/sw/nix/store/b4q5asj8flwlgmaijgj1r6wbmnls5x8k-python-3.9.15-view/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      "Accuracy: 0.7743, F1 Score: 0.7809\n",
      "DINO\n",
      "Epoch 0: Train Loss: 0.7210, Validation Loss: 0.7086\n",
      "Epoch 25: Train Loss: 0.6992, Validation Loss: 0.7012\n",
      "Epoch 50: Train Loss: 0.6968, Validation Loss: 0.7008\n",
      "Epoch 75: Train Loss: 0.6958, Validation Loss: 0.7007\n",
      "W20240311 12:32:06 3227326 py.warnings warnings.py:109] /mnt/sw/nix/store/b4q5asj8flwlgmaijgj1r6wbmnls5x8k-python-3.9.15-view/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      "Accuracy: 0.7774, F1 Score: 0.7780\n",
      "Stein\n",
      "Epoch 0: Train Loss: 0.7599, Validation Loss: 0.7568\n",
      "Epoch 25: Train Loss: 0.7068, Validation Loss: 0.7060\n",
      "Epoch 50: Train Loss: 0.7023, Validation Loss: 0.7025\n",
      "Epoch 75: Train Loss: 0.7014, Validation Loss: 0.7017\n",
      "W20240311 12:32:13 3227326 py.warnings warnings.py:109] /mnt/sw/nix/store/b4q5asj8flwlgmaijgj1r6wbmnls5x8k-python-3.9.15-view/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      "Accuracy: 0.7688, F1 Score: 0.7589\n"
     ]
    }
   ],
   "source": [
    "# Get Results for Bulge Prominence Question \n",
    "\n",
    "question, num_classes = 'Bulge Prominence', 4\n",
    "\n",
    "counts = classifications['t05_bulge_prominence_a10_no_bulge_count'] + classifications['t05_bulge_prominence_a11_just_noticeable_count'] + classifications['t05_bulge_prominence_a12_obvious_count'] + classifications['t05_bulge_prominence_a13_dominant_count']\n",
    "total = classifications['total_classifications']\n",
    "pct_answered = np.array(counts/total)\n",
    "above50 = np.where(pct_answered > .5)[0]\n",
    "\n",
    "y = classifications['t05_bulge_prominence_a10_no_bulge_fraction', 't05_bulge_prominence_a11_just_noticeable_fraction', 't05_bulge_prominence_a12_obvious_fraction', 't05_bulge_prominence_a13_dominant_fraction']\n",
    "y = torch.tensor(y[above50])\n",
    "\n",
    "print('CLIP')\n",
    "outputs['CLIP'][question] = train_eval_MLP(X_CLIP[above50], y, embed_dim=512, num_classes=num_classes, MLP_dim=32, epochs=100)\n",
    "\n",
    "print('DINO')\n",
    "outputs['DINO'][question] = train_eval_MLP(X_DINO[above50], y, embed_dim=1024, num_classes=num_classes, MLP_dim=32, epochs=100)\n",
    "\n",
    "print('Stein')\n",
    "outputs['Stein'][question] = train_eval_MLP(X_Stein[above50], y, embed_dim=128, num_classes=num_classes, MLP_dim=32, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP\n",
      "Epoch 0: Train Loss: 0.7130, Validation Loss: 0.7067\n",
      "Epoch 25: Train Loss: 0.6968, Validation Loss: 0.7030\n",
      "Epoch 50: Train Loss: 0.6939, Validation Loss: 0.7050\n",
      "Epoch 75: Train Loss: 0.6932, Validation Loss: 0.7036\n",
      "W20240311 12:32:44 3227326 py.warnings warnings.py:109] /mnt/sw/nix/store/b4q5asj8flwlgmaijgj1r6wbmnls5x8k-python-3.9.15-view/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      "Accuracy: 0.6124, F1 Score: 0.5721\n",
      "DINO\n",
      "Epoch 0: Train Loss: 0.6970, Validation Loss: 0.6850\n",
      "Epoch 25: Train Loss: 0.6711, Validation Loss: 0.6741\n",
      "Epoch 50: Train Loss: 0.6700, Validation Loss: 0.6743\n",
      "Epoch 75: Train Loss: 0.6694, Validation Loss: 0.6743\n",
      "W20240311 12:33:18 3227326 py.warnings warnings.py:109] /mnt/sw/nix/store/b4q5asj8flwlgmaijgj1r6wbmnls5x8k-python-3.9.15-view/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      "Accuracy: 0.7510, F1 Score: 0.7006\n",
      "Stein\n",
      "Epoch 0: Train Loss: 0.7504, Validation Loss: 0.7348\n",
      "Epoch 25: Train Loss: 0.7228, Validation Loss: 0.7231\n",
      "Epoch 50: Train Loss: 0.7202, Validation Loss: 0.7208\n",
      "Epoch 75: Train Loss: 0.7183, Validation Loss: 0.7192\n",
      "W20240311 12:33:45 3227326 py.warnings warnings.py:109] /mnt/sw/nix/store/b4q5asj8flwlgmaijgj1r6wbmnls5x8k-python-3.9.15-view/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      "Accuracy: 0.5648, F1 Score: 0.5233\n"
     ]
    }
   ],
   "source": [
    "# Get Results for How Rounded Question\n",
    "\n",
    "question, num_classes = 'How Rounded', 3\n",
    "\n",
    "counts = classifications['t07_rounded_a16_completely_round_count'] + classifications['t07_rounded_a17_in_between_count'] + classifications['t07_rounded_a18_cigar_shaped_count']\n",
    "total = classifications['total_classifications']\n",
    "pct_answered = np.array(counts/total)\n",
    "above50 = np.where(pct_answered > .5)[0]\n",
    "\n",
    "y = classifications['t07_rounded_a16_completely_round_fraction', 't07_rounded_a17_in_between_fraction', 't07_rounded_a18_cigar_shaped_fraction']\n",
    "y = torch.tensor(y[above50])\n",
    "\n",
    "print('CLIP')\n",
    "outputs['CLIP'][question] = train_eval_MLP(X_CLIP[above50], y, embed_dim=512, num_classes=num_classes, MLP_dim=32, epochs=100)\n",
    "\n",
    "print('DINO')\n",
    "outputs['DINO'][question] = train_eval_MLP(X_DINO[above50], y, embed_dim=1024, num_classes=num_classes, MLP_dim=32, epochs=100)\n",
    "\n",
    "print('Stein')\n",
    "outputs['Stein'][question] = train_eval_MLP(X_Stein[above50], y, embed_dim=128, num_classes=num_classes, MLP_dim=32, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP\n",
      "Epoch 0: Train Loss: 0.7188, Validation Loss: 0.6787\n",
      "Epoch 25: Train Loss: 0.5866, Validation Loss: 0.5894\n",
      "Epoch 50: Train Loss: 0.5866, Validation Loss: 0.5894\n",
      "Epoch 75: Train Loss: 0.5865, Validation Loss: 0.5894\n",
      "W20240311 12:33:46 3227326 py.warnings warnings.py:109] /mnt/sw/nix/store/b4q5asj8flwlgmaijgj1r6wbmnls5x8k-python-3.9.15-view/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      "Accuracy: 0.9679, F1 Score: 0.9483\n",
      "DINO\n",
      "Epoch 0: Train Loss: 0.7435, Validation Loss: 0.7043\n",
      "Epoch 25: Train Loss: 0.5868, Validation Loss: 0.5896\n",
      "Epoch 50: Train Loss: 0.5866, Validation Loss: 0.5894\n",
      "Epoch 75: Train Loss: 0.5866, Validation Loss: 0.5894\n",
      "W20240311 12:33:47 3227326 py.warnings warnings.py:109] /mnt/sw/nix/store/b4q5asj8flwlgmaijgj1r6wbmnls5x8k-python-3.9.15-view/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      "Accuracy: 0.9679, F1 Score: 0.9483\n",
      "Stein\n",
      "Epoch 0: Train Loss: 0.7679, Validation Loss: 0.7660\n",
      "Epoch 25: Train Loss: 0.6119, Validation Loss: 0.6124\n",
      "Epoch 50: Train Loss: 0.5904, Validation Loss: 0.5930\n",
      "Epoch 75: Train Loss: 0.5881, Validation Loss: 0.5909\n",
      "W20240311 12:33:48 3227326 py.warnings warnings.py:109] /mnt/sw/nix/store/b4q5asj8flwlgmaijgj1r6wbmnls5x8k-python-3.9.15-view/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      "Accuracy: 0.9679, F1 Score: 0.9483\n"
     ]
    }
   ],
   "source": [
    "# Get Results for Bulge Shape Question\n",
    "\n",
    "question, num_classes = 'Bulge Shape', 3\n",
    "\n",
    "counts = classifications['t09_bulge_shape_a25_rounded_count'] + classifications['t09_bulge_shape_a26_boxy_count'] + classifications['t09_bulge_shape_a27_no_bulge_count']\n",
    "total = classifications['total_classifications']\n",
    "pct_answered = np.array(counts/total)\n",
    "above50 = np.where(pct_answered > .5)[0]\n",
    "\n",
    "y = classifications['t07_rounded_a16_completely_round_fraction', 't07_rounded_a17_in_between_fraction', 't07_rounded_a18_cigar_shaped_fraction']\n",
    "y = torch.tensor(y[above50])\n",
    "\n",
    "print('CLIP')\n",
    "outputs['CLIP'][question] = train_eval_MLP(X_CLIP[above50], y, embed_dim=512, num_classes=num_classes, MLP_dim=32, epochs=100)\n",
    "\n",
    "print('DINO')\n",
    "outputs['DINO'][question] = train_eval_MLP(X_DINO[above50], y, embed_dim=1024, num_classes=num_classes, MLP_dim=32, epochs=100)\n",
    "\n",
    "print('Stein')\n",
    "outputs['Stein'][question] = train_eval_MLP(X_Stein[above50], y, embed_dim=128, num_classes=num_classes, MLP_dim=32, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP\n",
      "Epoch 0: Train Loss: 0.7481, Validation Loss: 0.7432\n",
      "Epoch 25: Train Loss: 0.7274, Validation Loss: 0.7339\n",
      "Epoch 50: Train Loss: 0.7216, Validation Loss: 0.7356\n",
      "Epoch 75: Train Loss: 0.7179, Validation Loss: 0.7368\n",
      "Accuracy: 0.4946, F1 Score: 0.5190\n",
      "DINO\n",
      "Epoch 0: Train Loss: 0.7459, Validation Loss: 0.7421\n",
      "Epoch 25: Train Loss: 0.7222, Validation Loss: 0.7274\n",
      "Epoch 50: Train Loss: 0.7179, Validation Loss: 0.7288\n",
      "Epoch 75: Train Loss: 0.7151, Validation Loss: 0.7296\n",
      "Accuracy: 0.5800, F1 Score: 0.5989\n",
      "Stein\n",
      "Epoch 0: Train Loss: 0.7630, Validation Loss: 0.7613\n",
      "Epoch 25: Train Loss: 0.7445, Validation Loss: 0.7454\n",
      "Epoch 50: Train Loss: 0.7436, Validation Loss: 0.7443\n",
      "Epoch 75: Train Loss: 0.7431, Validation Loss: 0.7437\n",
      "W20240311 12:34:05 3227326 py.warnings warnings.py:109] /mnt/sw/nix/store/b4q5asj8flwlgmaijgj1r6wbmnls5x8k-python-3.9.15-view/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      "Accuracy: 0.5054, F1 Score: 0.4621\n"
     ]
    }
   ],
   "source": [
    "# Get Results for Spiral Arm Type\n",
    "\n",
    "question, num_classes = 'Spiral Arm Type', 3\n",
    "\n",
    "counts = classifications['t10_arms_winding_a28_tight_count'] + classifications['t10_arms_winding_a29_medium_count'] + classifications['t10_arms_winding_a30_loose_count']\n",
    "total = classifications['total_classifications']\n",
    "pct_answered = np.array(counts/total)\n",
    "above50 = np.where(pct_answered > .5)[0]\n",
    "\n",
    "y = classifications['t10_arms_winding_a28_tight_fraction', 't10_arms_winding_a29_medium_fraction', 't10_arms_winding_a30_loose_fraction']\n",
    "y = torch.tensor(y[above50])\n",
    "\n",
    "print('CLIP')\n",
    "outputs['CLIP'][question] = train_eval_MLP(X_CLIP[above50], y, embed_dim=512, num_classes=num_classes, MLP_dim=32, epochs=100)\n",
    "\n",
    "print('DINO')\n",
    "outputs['DINO'][question] = train_eval_MLP(X_DINO[above50], y, embed_dim=1024, num_classes=num_classes, MLP_dim=32, epochs=100)\n",
    "\n",
    "print('Stein')\n",
    "outputs['Stein'][question] = train_eval_MLP(X_Stein[above50], y, embed_dim=128, num_classes=num_classes, MLP_dim=32, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP\n",
      "Epoch 0: Train Loss: 0.7196, Validation Loss: 0.7064\n",
      "Epoch 25: Train Loss: 0.7057, Validation Loss: 0.7051\n",
      "Epoch 50: Train Loss: 0.7034, Validation Loss: 0.7047\n",
      "Epoch 75: Train Loss: 0.7011, Validation Loss: 0.7054\n",
      "W20240311 12:34:10 3227326 py.warnings warnings.py:109] /mnt/sw/nix/store/b4q5asj8flwlgmaijgj1r6wbmnls5x8k-python-3.9.15-view/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      "Accuracy: 0.6466, F1 Score: 0.5951\n",
      "DINO\n",
      "Epoch 0: Train Loss: 0.7188, Validation Loss: 0.7056\n",
      "Epoch 25: Train Loss: 0.7055, Validation Loss: 0.7050\n",
      "Epoch 50: Train Loss: 0.7013, Validation Loss: 0.7033\n",
      "Epoch 75: Train Loss: 0.7002, Validation Loss: 0.7035\n",
      "W20240311 12:34:17 3227326 py.warnings warnings.py:109] /mnt/sw/nix/store/b4q5asj8flwlgmaijgj1r6wbmnls5x8k-python-3.9.15-view/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      "Accuracy: 0.6430, F1 Score: 0.5935\n",
      "Stein\n",
      "Epoch 0: Train Loss: 0.7528, Validation Loss: 0.7510\n",
      "Epoch 25: Train Loss: 0.7059, Validation Loss: 0.7052\n",
      "Epoch 50: Train Loss: 0.7058, Validation Loss: 0.7051\n",
      "Epoch 75: Train Loss: 0.7058, Validation Loss: 0.7051\n",
      "W20240311 12:34:22 3227326 py.warnings warnings.py:109] /mnt/sw/nix/store/b4q5asj8flwlgmaijgj1r6wbmnls5x8k-python-3.9.15-view/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      "Accuracy: 0.6358, F1 Score: 0.5089\n"
     ]
    }
   ],
   "source": [
    "# Get Results for Spiral Arm Count\n",
    "\n",
    "question, num_classes = 'Spiral Arm Count', 6\n",
    "\n",
    "counts = classifications['t11_arms_number_a31_1_count'] + classifications['t11_arms_number_a32_2_count'] + classifications['t11_arms_number_a33_3_count'] + classifications['t11_arms_number_a34_4_count'] + classifications['t11_arms_number_a36_more_than_4_count'] + classifications['t11_arms_number_a37_cant_tell_count']\n",
    "total = classifications['total_classifications']\n",
    "pct_answered = np.array(counts/total)\n",
    "above50 = np.where(pct_answered > .5)[0]\n",
    "\n",
    "y = classifications['t11_arms_number_a31_1_fraction', 't11_arms_number_a32_2_fraction', 't11_arms_number_a33_3_fraction', 't11_arms_number_a34_4_fraction', 't11_arms_number_a36_more_than_4_fraction', 't11_arms_number_a37_cant_tell_fraction']\n",
    "y = torch.tensor(y[above50])\n",
    "\n",
    "print('CLIP')\n",
    "outputs['CLIP'][question] = train_eval_MLP(X_CLIP[above50], y, embed_dim=512, num_classes=num_classes, MLP_dim=32, epochs=100)\n",
    "\n",
    "print('DINO')\n",
    "outputs['DINO'][question] = train_eval_MLP(X_DINO[above50], y, embed_dim=1024, num_classes=num_classes, MLP_dim=32, epochs=100)\n",
    "\n",
    "print('Stein')\n",
    "outputs['Stein'][question] = train_eval_MLP(X_Stein[above50], y, embed_dim=128, num_classes=num_classes, MLP_dim=32, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_radar(outputs, metric, file_path, title='Galaxy Property Estimation', fontsize=22):\n",
    "    questions = {}\n",
    "    for key in outputs.keys():\n",
    "        questions[key] = [outputs[key][question][metric] for question in outputs[key].keys()]\n",
    "\n",
    "    # Create radar chart\n",
    "    angles = np.linspace(0, 2 * pi, len(questions[key]), endpoint=False).tolist()\n",
    "    angles += angles[:1]  # complete the loop\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(12, 12), subplot_kw=dict(polar=True))\n",
    "\n",
    "    # Plot each array on the radar chart\n",
    "    for key in questions.keys():\n",
    "        stats = questions[key]\n",
    "        stats += stats[:1]  \n",
    "        ax.plot(angles, stats, label=key)\n",
    "\n",
    "    labels = outputs[key].keys()\n",
    "\n",
    "    # Add labels with specific fontsize\n",
    "    ax.set_theta_offset(pi / 2)\n",
    "    ax.set_theta_direction(-1)\n",
    "\n",
    "    # Change r label to fontsize\n",
    "    ax.tick_params(axis='y', labelsize=fontsize)\n",
    "\n",
    "    ax.set_xticks(angles[:-1])\n",
    "    ax.set_xticklabels(labels, fontsize=fontsize)  # Explicitly set fontsize for xtick labels\n",
    "\n",
    "    # make theta labels not overlap with plot    \n",
    "    ax.set_ylim(0, 1)\n",
    "\n",
    "    # Add legend and title with specific fontsize\n",
    "    legend = plt.legend(loc='upper right', bbox_to_anchor=(1.1, 1.1))\n",
    "    plt.setp(legend.get_texts(), fontsize=fontsize)  # Explicitly set fontsize for legend\n",
    "\n",
    "    plt.savefig(file_path)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_radar(outputs, 'Accuracy', title='Galaxy Property Estimation', file_path = 'accuracy.png', fontsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_radar(outputs, 'F1 Score', title='Galaxy Property Estimation', file_path = 'f1_score.png', fontsize=16)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "astroclip",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
