{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "\n",
    "sys.path.append(\"../..\")\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from astropy.table import Table\n",
    "\n",
    "from astroclip.env import format_with_env\n",
    "from morphology_utils.models import train_eval_on_question\n",
    "from morphology_utils.plotting import plot_radar\n",
    "\n",
    "ASTROCLIP_ROOT = format_with_env(\"{ASTROCLIP_ROOT}\")\n",
    "\n",
    "\n",
    "# Load the data\n",
    "galaxy_zoo = Table.read(\n",
    "    f\"{ASTROCLIP_ROOT}/datasets/galaxy_zoo/gz5_decals_crossmatched_embeddings.h5\"\n",
    ")\n",
    "\n",
    "# Remove the galaxies with fewer than 3 votes\n",
    "galaxy_zoo = galaxy_zoo[galaxy_zoo[\"smooth-or-featured_total-votes\"] >= 3]\n",
    "\n",
    "# Get the embeddings\n",
    "X = {\n",
    "    \"AstroCLIP\": torch.tensor(galaxy_zoo[\"astroclip_embeddings\"]),\n",
    "    \"AstroDINO\": torch.tensor(galaxy_zoo[\"astrodino_embeddings\"]),\n",
    "    \"Stein\": torch.tensor(galaxy_zoo[\"stein_embeddings\"]),\n",
    "}\n",
    "\n",
    "# Get the names of the columns\n",
    "names = names = [\n",
    "    \"smooth\",\n",
    "    \"disk-edge-on\",\n",
    "    \"spiral-arms\",\n",
    "    \"bar\",\n",
    "    \"bulge-size\",\n",
    "    \"how-rounded\",\n",
    "    \"edge-on-bulge\",\n",
    "    \"spiral-winding\",\n",
    "    \"spiral-arm-count\",\n",
    "    \"merging\",\n",
    "]\n",
    "\n",
    "# Get the labels\n",
    "galaxy_zoo.remove_columns(\n",
    "    [\"astroclip_embeddings\", \"astrodino_embeddings\", \"stein_embeddings\"]\n",
    ")\n",
    "classifications = galaxy_zoo\n",
    "\n",
    "# Get the key list\n",
    "keys = {\n",
    "    name: {\n",
    "        \"target\": [\n",
    "            key\n",
    "            for key in classifications.colnames\n",
    "            if name in key and \"debiased\" in key and \"mask\" not in key\n",
    "        ],\n",
    "        \"counts\": [\n",
    "            key\n",
    "            for key in classifications.colnames\n",
    "            if name in key and \"total-votes\" in key\n",
    "        ][0],\n",
    "    }\n",
    "    for name in names\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select first 80% for train and last 20% for test\n",
    "train_indices = int(0.8 * len(classifications))\n",
    "\n",
    "X_train, X_test = {}, {}\n",
    "for key in X.keys():\n",
    "    X_train[key] = X[key][:train_indices]\n",
    "    X_test[key] = X[key][train_indices:]\n",
    "\n",
    "classifications_train, classifications_test = (\n",
    "    classifications[:train_indices],\n",
    "    classifications[train_indices:],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the total number of possible votes\n",
    "total_counts_train = classifications_train[keys[\"smooth\"][\"counts\"]].data\n",
    "\n",
    "# Get accuracy and F1 score on each question\n",
    "outputs = {key: {} for key in X.keys()}\n",
    "for name in names:\n",
    "    question, num_classes = name, len(keys[name][\"target\"])\n",
    "\n",
    "    # Get the train samples above 50% answered\n",
    "    counts_train = classifications_train[keys[name][\"counts\"]].data\n",
    "    # train_mask = np.where(counts_train / total_counts_train > 0.5)[0]\n",
    "    train_mask = [True] * len(counts_train)\n",
    "\n",
    "    # Get the test samples above 34 answers\n",
    "    counts_test = classifications_test[keys[name][\"counts\"]].data\n",
    "    test_mask = np.where(counts_test > 34)[0]\n",
    "\n",
    "    # Get train and test\n",
    "    y_train = torch.tensor(\n",
    "        classifications_train[keys[name][\"target\"]].to_pandas().values\n",
    "    )[train_mask]\n",
    "    y_test = torch.tensor(\n",
    "        classifications_test[keys[name][\"target\"]].to_pandas().values\n",
    "    )[test_mask]\n",
    "\n",
    "    train_nan_mask = torch.isnan(y_train).any(axis=1)\n",
    "    test_nan_mask = torch.isnan(y_test).any(axis=1)\n",
    "\n",
    "    # Train and evaluate on each model\n",
    "    print(f\"Training on question: {question}...\")\n",
    "    for model in X.keys():\n",
    "        X_train_local = X_train[model][train_mask][~train_nan_mask]\n",
    "        X_test_local = X_test[model][test_mask][~test_nan_mask]\n",
    "        outputs[model][name] = train_eval_on_question(\n",
    "            X_train_local,\n",
    "            X_test_local,\n",
    "            y_train,\n",
    "            y_test,\n",
    "            X_train_local.shape[1],\n",
    "            num_classes=num_classes,\n",
    "            MLP_dim=256,\n",
    "            epochs=25,\n",
    "            dropout=0.2,\n",
    "        )\n",
    "        print(\n",
    "            f\"Model: {model}, Accuracy: {outputs[model][name]['Accuracy']:.4f}, F1: {outputs[model][name]['F1 Score']:.4f}\"\n",
    "        )\n",
    "    print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up labels\n",
    "outputs[\"Unaligned Transformer\"] = outputs.pop(\"AstroDINO\")\n",
    "outputs[\"Stein, et al.\"] = outputs.pop(\"Stein\")\n",
    "\n",
    "# Plot radar plots\n",
    "plot_radar(outputs, metric=\"Accuracy\", file_path=f\"./outputs/radar_accuracy.png\")\n",
    "plot_radar(outputs, metric=\"F1 Score\", file_path=f\"./outputs/radar_f1_score.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "toto",
   "language": "python",
   "name": "toto"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
