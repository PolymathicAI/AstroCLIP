{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from astropy.table import Table\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "from utils.models import few_shot, zero_shot\n",
    "from utils.plotting import plot_redshift_scatter\n",
    "\n",
    "PROVABGS_ROOT = \"/mnt/ceph/users/polymathic/astroclip/datasets/provabgs/\"\n",
    "SUPERVISED_ROOT = \"/mnt/ceph/users/polymathic/astroclip/supervised/\"\n",
    "\n",
    "# Define models in embeddings\n",
    "image_models = [\"astroclip_image\", \"astrodino\", \"stein\"]\n",
    "spectrum_models = [\"astroclip_spectrum\", \"specformer\"]\n",
    "\n",
    "# Set up the paths\n",
    "train_path = os.path.join(PROVABGS_ROOT, \"provabgs_paired_train_embeddings.hdf5\")\n",
    "test_path = os.path.join(PROVABGS_ROOT, \"provabgs_paired_test_embeddings.hdf5\")\n",
    "\n",
    "# Get embeddings and PROVABGS table\n",
    "train_provabgs = Table.read(train_path)\n",
    "test_provabgs = Table.read(test_path)\n",
    "\n",
    "# Get properties and scale\n",
    "properties = [\"Z_MW\", \"LOG_MSTAR\", \"TAGE_MW\", \"sSFR\"]\n",
    "y_train = np.stack([train_provabgs[prop].data.squeeze() for prop in properties]).T\n",
    "y_test = np.stack([test_provabgs[prop].data.squeeze() for prop in properties]).T\n",
    "scaler = {\"mean\": y_train.mean(axis=0), \"std\": y_train.std(axis=0)}\n",
    "y_train = (y_train - scaler[\"mean\"]) / scaler[\"std\"]\n",
    "\n",
    "print(\n",
    "    \"Size of training set:\",\n",
    "    len(train_provabgs),\n",
    "    \"\\nSize of test set:\",\n",
    "    len(test_provabgs),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Galaxy Property Prediction from Image Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data\n",
    "data = {}\n",
    "for model in image_models:\n",
    "    data[model] = {}\n",
    "    X_train, X_test = (\n",
    "        train_provabgs[model + \"_embeddings\"],\n",
    "        test_provabgs[model + \"_embeddings\"],\n",
    "    )\n",
    "    embedding_scaler = StandardScaler().fit(X_train)\n",
    "    data[model][\"train\"] = embedding_scaler.transform(X_train)\n",
    "    data[model][\"test\"] = embedding_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perfrom knn and mlp\n",
    "preds_knn, preds_mlp = {}, {}\n",
    "for key in data.keys():\n",
    "    print(f\"Evaluating {key} model...\")\n",
    "    raw_preds_knn = zero_shot(data[key][\"train\"], y_train, data[key][\"test\"])\n",
    "    raw_preds_mlp = few_shot(\n",
    "        model, data[key][\"train\"], y_train, data[key][\"test\"]\n",
    "    ).squeeze()\n",
    "    preds_knn[key] = raw_preds_knn * scaler[\"std\"] + scaler[\"mean\"]\n",
    "    preds_mlp[key] = raw_preds_mlp * scaler[\"std\"] + scaler[\"mean\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions from supervised models\n",
    "resnet_preds = torch.load(\n",
    "    os.path.join(SUPERVISED_ROOT, \"image/global_properties/test_pred.pt\")\n",
    ")\n",
    "photometry_preds = torch.load(\n",
    "    os.path.join(SUPERVISED_ROOT, \"photometry/global_properties/test_pred.pt\")\n",
    ")\n",
    "\n",
    "# Add predictions to dictionary\n",
    "preds_knn[\"resnet18\"] = np.stack(\n",
    "    [resnet_preds[prop].squeeze() for prop in properties]\n",
    ").T\n",
    "preds_knn[\"photometry\"] = np.stack(\n",
    "    [photometry_preds[prop].squeeze() for prop in properties]\n",
    ").T\n",
    "preds_mlp[\"resnet18\"] = np.stack(\n",
    "    [resnet_preds[prop].squeeze() for prop in properties]\n",
    ").T\n",
    "preds_mlp[\"photometry\"] = np.stack(\n",
    "    [photometry_preds[prop].squeeze() for prop in properties]\n",
    ").T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a table of r^2 scores\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "r2_scores = {key: {} for key in preds_knn.keys()}\n",
    "\n",
    "for key in preds_knn.keys():\n",
    "    for i, prop in enumerate(properties):\n",
    "        r2_scores[key][prop] = r2_score(y_test[:, i], preds_knn[key][:, i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "toto",
   "language": "python",
   "name": "toto"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
