{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.table import Table, join\n",
    "import torch\n",
    "import tqdm\n",
    "import numpy as np\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "\n",
    "import os, sys\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "from models import ResNet18, SpectrumEncoder, MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_supervised_data(\n",
    "    train_data: Table,\n",
    "    test_data: Table,\n",
    "    modality: str,\n",
    "    properties: list = None,\n",
    "    batch_size: int = 128,\n",
    "    train_size: float = 0.8,\n",
    "):\n",
    "    \"\"\"Helper function to set up supervised data for training and testing.\"\"\"\n",
    "    if properties is None:\n",
    "        properties = [\"Z_HP\", \"PROVABGS_LOG_MSTAR_BF\", \"Z_MW\", \"TAGE_MW\", \"AVG_SFR\"]\n",
    "\n",
    "    # Set up the training data\n",
    "    if modality == \"image\":\n",
    "        X_train, X_test = torch.tensor(\n",
    "            train_data[modality], dtype=torch.float32\n",
    "        ), torch.tensor(test_data[modality], dtype=torch.float32)\n",
    "\n",
    "    elif modality == \"spectrum\":\n",
    "        X_train, X_test = torch.tensor(\n",
    "            train_data[modality], dtype=torch.float32\n",
    "        ), torch.tensor(test_data[modality], dtype=torch.float32)\n",
    "        X_train = X_train.squeeze().squeeze()\n",
    "        X_test = X_test.squeeze().squeeze()\n",
    "\n",
    "    elif modality == \"photometry\":\n",
    "        X_train = torch.tensor(\n",
    "            np.stack([train_data[\"MAG_G\"], train_data[\"MAG_R\"], train_data[\"MAG_Z\"]]),\n",
    "            dtype=torch.float32,\n",
    "        ).permute(1, 0)\n",
    "        X_test = torch.tensor(\n",
    "            np.stack([test_data[\"MAG_G\"], test_data[\"MAG_R\"], test_data[\"MAG_Z\"]]),\n",
    "            dtype=torch.float32,\n",
    "        ).permute(1, 0)\n",
    "\n",
    "    # Scale the data\n",
    "    X_mean, X_std = X_train.mean(), X_train.std()\n",
    "    X_train = (X_train - X_mean) / X_std\n",
    "    X_test = (X_test - X_mean) / X_std\n",
    "\n",
    "    # Set up the property data\n",
    "    property_data, scale = {}, {}\n",
    "    for p in properties:\n",
    "        data = torch.tensor(train_data[p].data, dtype=torch.float32)\n",
    "        mean, std = data.mean(), data.std()\n",
    "        property_data[p] = ((data - mean) / std).squeeze()\n",
    "        scale[p] = {\"mean\": mean.numpy(), \"std\": std.numpy()}\n",
    "    y_train = torch.stack([property_data[p] for p in properties], dim=1)\n",
    "\n",
    "    # Split the data into training, validation, and test sets\n",
    "    total_size = len(X_train)\n",
    "    train_size = int(train_size * total_size)\n",
    "    train_dataset, val_dataset = random_split(\n",
    "        TensorDataset(X_train, y_train), [train_size, total_size - train_size]\n",
    "    )\n",
    "\n",
    "    # Set up the data loaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    test_loader = DataLoader(X_test, batch_size=batch_size, shuffle=False)\n",
    "    return train_loader, val_loader, test_loader, scale\n",
    "\n",
    "\n",
    "def train_model(\n",
    "    model: nn.Module,\n",
    "    train_loader: torch.utils.data.DataLoader,\n",
    "    val_loader: torch.utils.data.DataLoader,\n",
    "    scalers: dict[str, StandardScaler],\n",
    "    properties: list,\n",
    "    device=\"cuda\",\n",
    "    num_epochs=50,\n",
    "    learning_rate=1e-3,\n",
    "):\n",
    "    \"\"\"Helper function to train a model.\"\"\"\n",
    "    model.to(device)\n",
    "\n",
    "    # Define the loss function and optimizer\n",
    "    criterion = torch.nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=5e-4)\n",
    "\n",
    "    best_val_loss = float(\"inf\")\n",
    "\n",
    "    epochs = tqdm.trange(num_epochs, desc=\"Training Model: \", leave=True)\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in epochs:\n",
    "        train_loss = 0\n",
    "        model.train()\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            y_pred = model(X_batch.to(device)).squeeze()\n",
    "            loss = criterion(y_pred, y_batch.to(device))\n",
    "            train_loss += loss.item()\n",
    "\n",
    "            # Backward pass and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        val_pred, val_true, val_loss = [], [], 0\n",
    "        with torch.no_grad():\n",
    "            for X_batch, y_batch in val_loader:\n",
    "                y_pred = model(X_batch.to(device)).squeeze().detach().cpu()\n",
    "                loss = criterion(y_pred, y_batch)\n",
    "                val_loss += loss.item()\n",
    "                val_pred.append(y_pred)\n",
    "                val_true.append(y_batch)\n",
    "\n",
    "        val_pred = torch.cat(val_pred).numpy()\n",
    "        val_true = torch.cat(val_true).numpy()\n",
    "\n",
    "        val_r2s = {}\n",
    "        for i, prop in enumerate(scale.keys()):\n",
    "            pred_i = (val_pred[:, i] * scalers[prop][\"std\"]) + scalers[prop][\"mean\"]\n",
    "            true_i = (val_true[:, i] * scalers[prop][\"std\"]) + scalers[prop][\"mean\"]\n",
    "            val_r2s[prop] = r2_score(true_i, pred_i)\n",
    "\n",
    "        if val_loss / len(val_loader) < best_val_loss:\n",
    "            best_model = model.state_dict()\n",
    "            best_val_loss = val_loss / len(val_loader)\n",
    "\n",
    "        # Early stopping\n",
    "        if epoch > 10 and val_loss / len(val_loader) > 1.5 * best_val_loss:\n",
    "            break\n",
    "\n",
    "        epochs.set_description(\n",
    "            \"epoch: {}, train loss: {:.4f}, val loss: {:.4f}, z_hp: {:.4f}\".format(\n",
    "                epoch + 1,\n",
    "                train_loss / len(train_loader),\n",
    "                val_loss / len(val_loader),\n",
    "                val_r2s[\"Z_HP\"],\n",
    "            )\n",
    "        )\n",
    "        epochs.update(1)\n",
    "\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = (\n",
    "    \"/mnt/ceph/users/polymathic/astroclip/datasets/provabgs/provabgs_paired_train.hdf5\"\n",
    ")\n",
    "test_dataset = (\n",
    "    \"/mnt/ceph/users/polymathic/astroclip/datasets/provabgs/provabgs_paired_test.hdf5\"\n",
    ")\n",
    "properties = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if properties is None:\n",
    "    properties = [\"Z_HP\", \"PROVABGS_LOGMSTAR_BF\", \"Z_MW\", \"TAGE_MW\", \"AVG_SFR\"]\n",
    "\n",
    "# Load the data\n",
    "train_provabgs = Table.read(train_dataset)\n",
    "test_provabgs = Table.read(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the data loaders & scalers\n",
    "train_loader, val_loader, test_loader, scale = setup_supervised_data(\n",
    "    train_provabgs, test_provabgs, \"photometry\", properties=properties\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model\n",
    "# model = SpectrumEncoder(n_latent=5)\n",
    "model = MLP()\n",
    "\n",
    "# Train the model\n",
    "best_model = train_model(\n",
    "    model, train_loader, val_loader, scale, properties, num_epochs=1, learning_rate=5e-4\n",
    ")\n",
    "model.load_state_dict(best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = []\n",
    "with torch.no_grad():\n",
    "    for X_batch in test_loader:\n",
    "        y_pred = model(X_batch.to(device)).squeeze().detach().cpu()\n",
    "        test_pred.append(y_pred)\n",
    "test_pred = torch.cat(test_pred).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, p in enumerate(scale.keys()):\n",
    "    test_pred[:, i] = (test_pred[:, i] * scale[p][\"std\"]) + scale[p][\"mean\"]\n",
    "    print(r2_score(test_provabgs[p], test_pred[:, i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(\n",
    "    train_dataset: str, \n",
    "    test_datset: str, \n",
    "    save_dir: str,\n",
    "    modality: str,\n",
    "    num_epochs: int = 50, \n",
    "    learning_rate: float = 5e-4, \n",
    "    properties: list = None):\n",
    "\n",
    "    if properties is None:\n",
    "        properties = ['Z_HP', 'PROVABGS_LOGMSTAR_BF', 'Z_MW', 'TAGE_MW', 'AVG_SFR']\n",
    "\n",
    "    # Load the data\n",
    "    train_provabgs = Table.read(train_dataset)\n",
    "    test_provabgs = Table.read(test_dataset)\n",
    "\n",
    "    # Get the data loaders & scalers\n",
    "    train_loader, val_loader, test_loader, scale = setup_supervised_data(train_provabgs, test_provabgs, modality, properties=properties)\n",
    "\n",
    "    # Initialize the model\n",
    "    if modality == 'image':\n",
    "        model = ResNet18(num_classes=len(properties))\n",
    "    elif modality == 'spectrum':\n",
    "        model = \n",
    "\n",
    "    # Train the model\n",
    "    best_model = train_model(model, train_loader, val_loader, scale, properties, num_epochs=num_epochs, learning_rate=learning_rate)\n",
    "    model.load_state_dict(best_model)\n",
    "\n",
    "    # Get the predictions\n",
    "    test_pred = []\n",
    "    with torch.no_grad():\n",
    "        for X_batch in test_loader:\n",
    "            y_pred = model(X_batch.to(device)).squeeze().detach().cpu()\n",
    "            test_pred.append(y_pred)\n",
    "    test_pred = torch.cat(test_pred).numpy()\n",
    "\n",
    "    pred_dict = {}\n",
    "    for i, p in enumerate(scale.keys()):\n",
    "        pred_dict[p] = (test_pred[:, i] * scale[p]['std']) + scale[p]['mean']\n",
    "        print(f'{p} R^2: {r2_score(test_provabgs[p], pred_dict[p])}')\n",
    "\n",
    "    # Save the model and the predictions\n",
    "    torch.save(model, os.path.join(save_dir, 'resnet.pt'))\n",
    "    torch.save(pred_dict, os.path.join(save_dir, 'test_pred.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main(\n",
    "    \"/mnt/ceph/users/polymathic/astroclip/datasets/provabgs/provabgs_paired_train.hdf5\",\n",
    "    \"/mnt/ceph/users/polymathic/astroclip/datasets/provabgs/provabgs_paired_test.hdf5\",\n",
    "    \"/mnt/ceph/users/polymathic/astroclip/supervised/\",\n",
    "    num_epochs=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "toto",
   "language": "python",
   "name": "toto"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
