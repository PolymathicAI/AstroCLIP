{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from astropy.table import Table, join\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from utils.models import MLP, zero_shot, few_shot\n",
    "\n",
    "supervised_path = \"/mnt/ceph/users/polymathic/astroclip/supervised/\"\n",
    "\n",
    "# Load the data\n",
    "train_provabgs = Table.read(\n",
    "    \"/mnt/ceph/users/polymathic/astroclip/datasets/provabgs/provabgs_paired_train_embeddings.hdf5\"\n",
    ")\n",
    "test_provabgs = Table.read(\n",
    "    \"/mnt/ceph/users/polymathic/astroclip/datasets/provabgs/provabgs_paired_test_embeddings.hdf5\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\"astrodino\", \"stein\"]\n",
    "\n",
    "# Get data\n",
    "data = {}\n",
    "for model in models:\n",
    "    data[model] = {}\n",
    "    X_train, X_test = (\n",
    "        train_provabgs[model + \"_embeddings\"],\n",
    "        test_provabgs[model + \"_embeddings\"],\n",
    "    )\n",
    "    embedding_scaler = StandardScaler().fit(X_train)\n",
    "    data[model][\"train\"] = embedding_scaler.transform(X_train)\n",
    "    data[model][\"test\"] = embedding_scaler.transform(X_test)\n",
    "\n",
    "# Get redshifts\n",
    "z_train = train_provabgs[\"Z_HP\"]\n",
    "z_test = test_provabgs[\"Z_HP\"]\n",
    "\n",
    "# Scale properties\n",
    "scaler = {\"mean\": z_train.mean(), \"std\": z_train.std()}\n",
    "z_train = (z_train - scaler[\"mean\"]) / scaler[\"std\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from numpy import ndarray\n",
    "\n",
    "\n",
    "class MLP(nn.Sequential):\n",
    "    \"\"\"MLP model\"\"\"\n",
    "\n",
    "    def __init__(self, n_in, n_out, n_hidden=(16, 16, 16), act=None, dropout=0):\n",
    "        if act is None:\n",
    "            act = [\n",
    "                nn.LeakyReLU(),\n",
    "            ] * (len(n_hidden) + 1)\n",
    "        assert len(act) == len(n_hidden) + 1\n",
    "\n",
    "        layer = []\n",
    "        n_ = [n_in, *n_hidden, n_out]\n",
    "        for i in range(len(n_) - 2):\n",
    "            layer.append(nn.Linear(n_[i], n_[i + 1]))\n",
    "            layer.append(act[i])\n",
    "            layer.append(nn.Dropout(p=dropout))\n",
    "        layer.append(nn.Linear(n_[-2], n_[-1]))\n",
    "\n",
    "        super(MLP, self).__init__(*layer)\n",
    "\n",
    "\n",
    "def few_shot(\n",
    "    model: nn.Module,\n",
    "    X_train: ndarray,\n",
    "    y_train: ndarray,\n",
    "    X_test: ndarray,\n",
    "    max_epochs: int = 10,\n",
    "    lr: float = 1e-3,\n",
    ") -> ndarray:\n",
    "    \"\"\"Train a few-shot model using a simple neural network\"\"\"\n",
    "    train_dataset = TensorDataset(\n",
    "        torch.tensor(X_train, dtype=torch.float32),\n",
    "        torch.tensor(y_train, dtype=torch.float32),\n",
    "    )\n",
    "    train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "    num_features = y_train.shape[1] if len(y_train.shape) > 1 else 1\n",
    "    model = MLP(\n",
    "        n_in=X_train.shape[1],\n",
    "        n_out=num_features,\n",
    "        n_hidden=[64, 64],\n",
    "        act=[nn.ReLU()] * 3,\n",
    "    )\n",
    "\n",
    "    # Set up the model\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    # Train the model\n",
    "    model.cuda()\n",
    "    model.train()\n",
    "    for epoch in range(max_epochs):\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(train_loader, 0):\n",
    "            inputs, labels = data\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs.cuda()).squeeze()\n",
    "            loss = criterion(outputs, labels.cuda())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "    # Make predictions\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        preds = model(torch.tensor(X_test, dtype=torch.float32).cuda()).cpu().numpy()\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_knn, preds_mlp = {}, {}\n",
    "\n",
    "for key in data.keys():\n",
    "    raw_preds_knn = zero_shot(data[key][\"train\"], z_train, data[key][\"test\"])\n",
    "    if key == \"stein\":\n",
    "        model = MLP(128, 1, n_hidden=[128, 64, 32])\n",
    "    else:\n",
    "        model = MLP(1024, 1, n_hidden=[128, 64, 32])\n",
    "\n",
    "    raw_preds_mlp = few_shot(\n",
    "        model, data[key][\"train\"], z_train, data[key][\"test\"], max_epochs=20\n",
    "    ).squeeze()\n",
    "    preds_knn[key] = raw_preds_knn * scaler[\"std\"] + scaler[\"mean\"]\n",
    "    preds_mlp[key] = raw_preds_mlp * scaler[\"std\"] + scaler[\"mean\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions from supervised models\n",
    "resnet_preds = torch.load(os.path.join(supervised_path, \"image/test_pred.pt\"))[\"Z_HP\"]\n",
    "photometry_preds = torch.load(os.path.join(supervised_path, \"photometry/test_pred.pt\"))[\n",
    "    \"Z_HP\"\n",
    "]\n",
    "\n",
    "preds_knn[\"resnet18\"] = resnet_preds\n",
    "preds_knn[\"photometry\"] = photometry_preds\n",
    "preds_mlp[\"resnet18\"] = resnet_preds\n",
    "preds_mlp[\"photometry\"] = photometry_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_redshift_scatter(preds, z_test, save_loc=\"scatter.png\"):\n",
    "    fig, ax = plt.subplots(2, len(preds.keys()), figsize=(16, 10))\n",
    "\n",
    "    for i, name in enumerate(preds.keys()):\n",
    "        sns.scatterplot(ax=ax[0, i], x=z_test, y=preds[name], s=5, color=\".15\")\n",
    "        sns.histplot(\n",
    "            ax=ax[0, i], x=z_test, y=preds[name], bins=50, pthresh=0.1, cmap=\"mako\"\n",
    "        )\n",
    "        sns.kdeplot(\n",
    "            ax=ax[0, i], x=z_test, y=preds[name], levels=5, color=\"k\", linewidths=1\n",
    "        )\n",
    "\n",
    "        ax[0, i].plot(0, 0.65, \"--\", linewidth=1.5, alpha=0.5, color=\"grey\")\n",
    "        ax[0, i].set_xlim(0, 0.6)\n",
    "        ax[0, i].set_ylim(0, 0.6)\n",
    "        ax[0, i].text(\n",
    "            0.9,\n",
    "            0.1,\n",
    "            \"$R^2$ score: %0.2f\" % r2_score(z_test, preds[name]),\n",
    "            horizontalalignment=\"right\",\n",
    "            verticalalignment=\"top\",\n",
    "            fontsize=22,\n",
    "            transform=ax[0, i].transAxes,\n",
    "        )\n",
    "        ax[0, i].set_title(name, fontsize=25)\n",
    "\n",
    "    ax[0, 0].set_ylabel(\"$Z_{pred}$\", fontsize=25)\n",
    "\n",
    "    for i, name in enumerate(preds.keys()):\n",
    "        x = z_test\n",
    "        y = (z_test - preds[name]) / (1 + z_test)\n",
    "\n",
    "        bins = np.linspace(0, 0.62, 20)\n",
    "        x_binned = np.digitize(x, bins)\n",
    "        y_avg = [y[x_binned == i].mean() for i in range(1, len(bins))]\n",
    "        y_std = [y[x_binned == i].std() for i in range(1, len(bins))]\n",
    "\n",
    "        sns.scatterplot(ax=ax[1, i], x=x, y=y, s=2, alpha=0.3, color=\"black\")\n",
    "        sns.lineplot(ax=ax[1, i], x=bins[:-1], y=y_std, color=\"r\", label=\"std\")\n",
    "\n",
    "        # horizontal line on y = 0\n",
    "        ax[1, i].axhline(0, color=\"grey\", linewidth=1.5, alpha=0.5, linestyle=\"--\")\n",
    "\n",
    "        # sns.scatterplot(ax=ax[1,i], x=bins[:-1], y=y_avg, s=15, color='.15')\n",
    "        ax[1, i].set_xlim(0, 0.6)\n",
    "        ax[1, i].set_ylim(-0.3, 0.3)\n",
    "        ax[1, i].set_xlabel(\"$Z_{true}$\", fontsize=25)\n",
    "        ax[1, i].legend(fontsize=15, loc=\"upper right\")\n",
    "\n",
    "    ax[1, 0].set_ylabel(\"$(Z_{true}-Z_{pred})/(1+Z_{true})$\", fontsize=25)\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.97])\n",
    "    plt.savefig(save_loc, dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_redshift_scatter(preds_knn, z_test, save_loc=\"scatter_knn.png\")\n",
    "plot_redshift_scatter(preds_mlp, z_test, save_loc=\"scatter_mlp.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "toto",
   "language": "python",
   "name": "toto"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
