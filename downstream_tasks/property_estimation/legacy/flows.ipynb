{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9625e80-ce8d-4f86-8d55-9dc8d7155bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "\n",
    "from astropy.table import Table, join\n",
    "from datasets import load_dataset\n",
    "import h5py\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import seaborn as sns\n",
    "from math import pi\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from utils.helpers import (\n",
    "    zero_shot_train,\n",
    "    few_shot_train,\n",
    "    plot_radar,\n",
    "    resnet_r2,\n",
    "    photometry_r2,\n",
    "    spender_r2,\n",
    ")\n",
    "from utils.models import SimpleMLP\n",
    "\n",
    "# Rewritten with CUDA support\n",
    "from pyro.distributions.transforms import ComposeTransform\n",
    "import torch\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "import pyro.distributions.transforms as T\n",
    "from torch.distributions.transforms import Transform\n",
    "from torch.distributions.utils import lazy_property\n",
    "from pyro.distributions import constraints\n",
    "import tqdm\n",
    "\n",
    "sns.set_style(\"ticks\")\n",
    "sns.set_context(\"paper\", font_scale=1.5, rc={\"lines.linewidth\": 2})\n",
    "\n",
    "# Overall Definitions:\n",
    "properties = [\"Z_HP\", \"LOG_MSTAR\", \"Z_MW\", \"t_ageMW\", \"SFR\"]\n",
    "property_titles = [\n",
    "    \"$Z_{HP}$\",\n",
    "    \"$\\log {M_\\star}$\",\n",
    "    \"$\\log Z_{MW}$\",\n",
    "    \"$t_{age}$\",\n",
    "    \"$\\log sSFR$\",\n",
    "]\n",
    "scaler = StandardScaler()\n",
    "\n",
    "\n",
    "# ----- Replace with new Dataset Loader ----- #\n",
    "def get_embeddings(embedding_file, source=\"images\"):\n",
    "    CLIP_embeddings = h5py.File(embedding_file, \"r\")\n",
    "    train_embeddings = CLIP_embeddings[\"train\"]\n",
    "    test_embeddings = CLIP_embeddings[\"test\"]\n",
    "\n",
    "    if source == \"images\":\n",
    "        train_table = Table(\n",
    "            {\n",
    "                \"targetid\": train_embeddings[\"targetid\"],\n",
    "                \"image_features\": train_embeddings[\"image_features\"],\n",
    "            }\n",
    "        )\n",
    "\n",
    "        test_table = Table(\n",
    "            {\n",
    "                \"targetid\": test_embeddings[\"targetid\"],\n",
    "                \"image_features\": test_embeddings[\"image_features\"],\n",
    "            }\n",
    "        )\n",
    "\n",
    "    elif source == \"spectra\":\n",
    "        train_table = Table(\n",
    "            {\n",
    "                \"targetid\": train_embeddings[\"targetid\"],\n",
    "                \"spectra_features\": train_embeddings[\"spectra_features\"],\n",
    "            }\n",
    "        )\n",
    "\n",
    "        test_table = Table(\n",
    "            {\n",
    "                \"targetid\": test_embeddings[\"targetid\"],\n",
    "                \"spectra_features\": test_embeddings[\"spectra_features\"],\n",
    "            }\n",
    "        )\n",
    "\n",
    "    elif source == \"photometry\":\n",
    "        train_table = Table({\"targetid\": train_embeddings[\"targetid\"]})\n",
    "        test_table = Table({\"targetid\": test_embeddings[\"targetid\"]})\n",
    "\n",
    "    return train_table, test_table\n",
    "\n",
    "\n",
    "def get_provabgs(embedding_file, source=\"images\"):\n",
    "    provabgs = Table.read(\"/mnt/home/lparker/ceph/BGS_ANY_full.provabgs.sv3.v0.hdf5\")\n",
    "    provabgs = provabgs[\n",
    "        (provabgs[\"LOG_MSTAR\"] > 0)\n",
    "        * (provabgs[\"MAG_G\"] > 0)\n",
    "        * (provabgs[\"MAG_R\"] > 0)\n",
    "        * (provabgs[\"MAG_Z\"] > 0)\n",
    "    ]\n",
    "    inds = np.random.permutation(len(provabgs))\n",
    "    provabgs = provabgs[inds]\n",
    "\n",
    "    if source == \"images\":\n",
    "        train_table, test_table = get_embeddings(embedding_file, source)\n",
    "        train_provabgs = join(\n",
    "            provabgs, train_table, keys_left=\"TARGETID\", keys_right=\"targetid\"\n",
    "        )\n",
    "        test_provabgs = join(\n",
    "            provabgs, test_table, keys_left=\"TARGETID\", keys_right=\"targetid\"\n",
    "        )\n",
    "\n",
    "    elif source == \"spectra\":\n",
    "        train_table, test_table = get_embeddings(embedding_file, source)\n",
    "        train_provabgs = join(\n",
    "            provabgs, train_table, keys_left=\"TARGETID\", keys_right=\"targetid\"\n",
    "        )\n",
    "        test_provabgs = join(\n",
    "            provabgs, test_table, keys_left=\"TARGETID\", keys_right=\"targetid\"\n",
    "        )\n",
    "\n",
    "    elif source == \"photometry\":\n",
    "        train_table, test_table = get_embeddings(embedding_file, source)\n",
    "        train_provabgs = join(\n",
    "            provabgs, train_table, keys_left=\"TARGETID\", keys_right=\"targetid\"\n",
    "        )\n",
    "        test_provabgs = join(\n",
    "            provabgs, test_table, keys_left=\"TARGETID\", keys_right=\"targetid\"\n",
    "        )\n",
    "\n",
    "    return train_provabgs, test_provabgs\n",
    "\n",
    "\n",
    "# -------------------------------------------- #\n",
    "\n",
    "\n",
    "def get_data(embedding_file, source=\"images\"):\n",
    "    train_provabgs, test_provabgs = get_provabgs(embedding_file, source)\n",
    "\n",
    "    # Scale the galaxy property data\n",
    "    prop_scalers = {}\n",
    "    y_train, y_test = np.zeros((len(train_provabgs), 5)), np.zeros(\n",
    "        (len(test_provabgs), 5)\n",
    "    )\n",
    "    for i, p in enumerate(properties):\n",
    "        prop_train, prop_test = train_provabgs[p].reshape(-1, 1), test_provabgs[\n",
    "            p\n",
    "        ].reshape(-1, 1)\n",
    "        if p == \"Z_MW\":\n",
    "            prop_train, prop_test = np.log(prop_train), np.log(prop_test)\n",
    "        prop_scaler = StandardScaler().fit(prop_train)\n",
    "        prop_train, prop_test = prop_scaler.transform(\n",
    "            prop_train\n",
    "        ), prop_scaler.transform(prop_test)\n",
    "        y_train[:, i], y_test[:, i] = prop_train.squeeze(), prop_test.squeeze()\n",
    "        prop_scalers[p] = prop_scaler\n",
    "\n",
    "    if source == \"images\":\n",
    "        train_images, test_images = (\n",
    "            train_provabgs[\"image_features\"],\n",
    "            test_provabgs[\"image_features\"],\n",
    "        )\n",
    "        image_scaler = StandardScaler().fit(train_images)\n",
    "        train_images, test_images = image_scaler.transform(\n",
    "            train_images\n",
    "        ), image_scaler.transform(test_images)\n",
    "\n",
    "        data = {\n",
    "            \"X_train\": torch.tensor(train_images),\n",
    "            \"X_test\": torch.tensor(test_images),\n",
    "            \"y_train\": torch.tensor(y_train, dtype=torch.float32),\n",
    "            \"y_test\": torch.tensor(y_test, dtype=torch.float32),\n",
    "        }\n",
    "\n",
    "    elif source == \"spectra\":\n",
    "        train_spectra, test_spectra = (\n",
    "            train_provabgs[\"spectra_features\"],\n",
    "            test_provabgs[\"spectra_features\"],\n",
    "        )\n",
    "        spectrum_scaler = StandardScaler().fit(train_spectra)\n",
    "        train_spectra, test_spectra = spectrum_scaler.transform(\n",
    "            train_spectra\n",
    "        ), spectrum_scaler.transform(test_spectra)\n",
    "\n",
    "        data = {\n",
    "            \"X_train\": torch.tensor(train_spectra),\n",
    "            \"X_test\": torch.tensor(test_spectra),\n",
    "            \"y_train\": torch.tensor(y_train, dtype=torch.float32),\n",
    "            \"y_test\": torch.tensor(y_test, dtype=torch.float32),\n",
    "        }\n",
    "\n",
    "    elif source == \"photometry\":\n",
    "        data = {\n",
    "            \"X_train\": torch.tensor(\n",
    "                train_provabgs[\"MAG_G\", \"MAG_R\", \"MAG_Z\"], dtype=torch.float32\n",
    "            ),\n",
    "            \"X_test\": torch.tensor(\n",
    "                test_provabgs[\"MAG_G\", \"MAG_R\", \"MAG_Z\"], dtype=torch.float32\n",
    "            ),\n",
    "            \"y_train\": torch.tensor(y_train, dtype=torch.float32),\n",
    "            \"y_test\": torch.tensor(y_test, dtype=torch.float32),\n",
    "        }\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Invalid source. Must be one of: images, spectra, photometry\")\n",
    "\n",
    "    return data, prop_scalers\n",
    "\n",
    "\n",
    "def get_supervised(source):\n",
    "    if source == \"resnet\":\n",
    "        resnet_results = torch.load(\"./baseline_models/resnet_results\")\n",
    "        data = {\n",
    "            \"X_train\": torch.tensor(resnet_results[\"train_preds\"]),\n",
    "            \"y_train\": torch.tensor(resnet_results[\"train_trues\"]),\n",
    "            \"X_test\": torch.tensor(resnet_results[\"test_preds\"]),\n",
    "            \"y_test\": torch.tensor(resnet_results[\"test_trues\"]),\n",
    "        }\n",
    "        scalers = resnet_results[\"scalers\"]\n",
    "\n",
    "    elif source == \"spender\":\n",
    "        spender_results = torch.load(\"./baseline_models/spender_results\")\n",
    "        data = {\n",
    "            \"X_train\": torch.tensor(spender_results[\"train_preds\"]),\n",
    "            \"y_train\": torch.tensor(spender_results[\"train_trues\"]),\n",
    "            \"X_test\": torch.tensor(spender_results[\"test_preds\"]),\n",
    "            \"y_test\": torch.tensor(spender_results[\"test_trues\"]),\n",
    "        }\n",
    "        scalers = spender_results[\"scalers\"]\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Invalid source. Must be one of: resnet, spender\")\n",
    "\n",
    "    return data, scalers\n",
    "\n",
    "\n",
    "class ConditionalFlowStack(dist.conditional.ConditionalComposeTransformModule):\n",
    "    def __init__(self, input_dim, context_dim, hidden_dims, num_flows):\n",
    "        coupling_transforms = [\n",
    "            T.conditional_spline(\n",
    "                input_dim,\n",
    "                context_dim,\n",
    "                count_bins=16,\n",
    "                hidden_dims=hidden_dims,\n",
    "                order=\"quadratic\",\n",
    "            ).cuda()\n",
    "            for _ in range(num_flows)\n",
    "        ]\n",
    "\n",
    "        super().__init__(coupling_transforms, cache_size=1)\n",
    "\n",
    "\n",
    "def train(\n",
    "    train_loader,\n",
    "    test_loader,\n",
    "    val_loader,\n",
    "    base_dist,\n",
    "    transform,\n",
    "    index,\n",
    "    num_epochs=100,\n",
    "    lr=5e-5,\n",
    "):\n",
    "    # Initialize the optimizer\n",
    "    optimizer = torch.optim.Adam(transform.parameters(), lr=lr)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "        optimizer, T_max=num_epochs, eta_min=1e-6\n",
    "    )\n",
    "    pyro.clear_param_store()\n",
    "\n",
    "    train_losses, val_losses = [], []\n",
    "    epochs = tqdm.trange(num_epochs, desc=\"Training flow %i\" % (index))\n",
    "    best_val_loss, best_transform = float(\"inf\"), None\n",
    "\n",
    "    for epoch in epochs:\n",
    "        avg_loss = 0\n",
    "        for X, y in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            flow_dist = dist.conditional.ConditionalTransformedDistribution(\n",
    "                base_dist, [transform]\n",
    "            ).condition(X.to(\"cuda\"))\n",
    "            train_loss = -flow_dist.log_prob(y.to(\"cuda\")).mean()\n",
    "            train_loss.backward()\n",
    "            optimizer.step()\n",
    "            flow_dist.clear_cache()\n",
    "            avg_loss += train_loss.item()\n",
    "        avg_loss /= len(train_loader)\n",
    "\n",
    "        avg_val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for X, y in val_loader:\n",
    "                flow_dist = dist.conditional.ConditionalTransformedDistribution(\n",
    "                    base_dist, [transform]\n",
    "                ).condition(X.to(\"cuda\"))\n",
    "                avg_val_loss -= flow_dist.log_prob(y.to(\"cuda\")).mean().item()\n",
    "                flow_dist.clear_cache()\n",
    "        avg_val_loss /= len(val_loader)\n",
    "\n",
    "        # add early stopping\n",
    "        if epoch > 20 and avg_val_loss > np.mean(val_losses[-20:]):\n",
    "            break\n",
    "\n",
    "        train_losses.append(avg_loss)\n",
    "        val_losses.append(avg_val_loss)\n",
    "\n",
    "        epochs.set_description(\n",
    "            \"step: {}, train loss: {}, val loss: {}\".format(\n",
    "                epoch, np.round(avg_loss, 3), np.round(avg_val_loss, 3)\n",
    "            )\n",
    "        )\n",
    "\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            best_transform = transform\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "    avg_test_loss = 0\n",
    "    for X, y in test_loader:\n",
    "        flow_dist = dist.conditional.ConditionalTransformedDistribution(\n",
    "            base_dist, [best_transform]\n",
    "        ).condition(X.to(\"cuda\"))\n",
    "        avg_test_loss -= flow_dist.log_prob(y.to(\"cuda\")).mean()\n",
    "        flow_dist.clear_cache()\n",
    "    avg_test_loss /= len(test_loader)\n",
    "\n",
    "    return best_transform, avg_test_loss\n",
    "\n",
    "\n",
    "def do_flow(\n",
    "    data,\n",
    "    num_ndes,\n",
    "    n_samples=500,\n",
    "    max_hidden=128,\n",
    "    max_flows=4,\n",
    "    min_flows=None,\n",
    "    num_epochs=100,\n",
    "    lr=5e-5,\n",
    "    batch_size=1024,\n",
    "):\n",
    "    if min_flows == None:\n",
    "        min_flows = max_flows - 2\n",
    "\n",
    "    X_train, X_test = data[\"X_train\"].to(\"cuda\"), data[\"X_test\"].to(\"cuda\")\n",
    "    y_train, y_test = data[\"y_train\"].to(\"cuda\"), data[\"y_test\"].to(\"cuda\")\n",
    "\n",
    "    X_train, X_val, y_train, y_val = (\n",
    "        X_train[: int(0.8 * len(X_train))],\n",
    "        X_train[int(0.8 * len(X_train)) :],\n",
    "        y_train[: int(0.8 * len(y_train))],\n",
    "        y_train[int(0.8 * len(y_train)) :],\n",
    "    )\n",
    "\n",
    "    train_loader = DataLoader(TensorDataset(X_train, y_train), batch_size=batch_size)\n",
    "    val_loader = DataLoader(TensorDataset(X_val, y_val), batch_size=batch_size)\n",
    "    test_loader = DataLoader(TensorDataset(X_test, y_test), batch_size=batch_size)\n",
    "\n",
    "    input_dim, context_dim = y_train.shape[1], X_train.shape[1]\n",
    "\n",
    "    base_dist = dist.Normal(\n",
    "        torch.zeros(input_dim).to(\"cuda\"), torch.ones(input_dim).to(\"cuda\")\n",
    "    )\n",
    "\n",
    "    flows, losses, samples = [], [], []\n",
    "    for i in range(num_ndes):\n",
    "        nhidden = int(\n",
    "            np.ceil(\n",
    "                np.exp(np.random.uniform(np.log(max_hidden / 4), np.log(max_hidden)))\n",
    "            )\n",
    "        )\n",
    "        nblocks = int(np.random.uniform(min_flows, max_flows))\n",
    "\n",
    "        print(\"Flow with nhidden=%i; ncomponents=%i:\" % (nhidden, nblocks))\n",
    "\n",
    "        transform = ConditionalFlowStack(\n",
    "            input_dim, context_dim, [nhidden, nhidden, nhidden], nblocks\n",
    "        ).to(\"cuda\")\n",
    "        flow, loss = train(\n",
    "            train_loader,\n",
    "            test_loader,\n",
    "            val_loader,\n",
    "            base_dist,\n",
    "            transform,\n",
    "            i,\n",
    "            num_epochs=num_epochs,\n",
    "            lr=lr,\n",
    "        )\n",
    "        print(\"Test Loss: %.3f\" % (loss))\n",
    "        flows.append(flow)\n",
    "        losses.append(loss)\n",
    "\n",
    "        print(\"Sampling flow...\")\n",
    "        flow_samples = torch.zeros((X_test.shape[0], 1000, 5))\n",
    "        with torch.no_grad():\n",
    "            for i, x in enumerate(X_test):\n",
    "                flow_dist = dist.conditional.ConditionalTransformedDistribution(\n",
    "                    base_dist, [flow]\n",
    "                ).condition(x)\n",
    "                flow_samples[i, :, :] = (\n",
    "                    flow_dist.sample(\n",
    "                        torch.Size(\n",
    "                            [\n",
    "                                n_samples,\n",
    "                            ]\n",
    "                        )\n",
    "                    )\n",
    "                    .detach()\n",
    "                    .cpu()\n",
    "                )\n",
    "\n",
    "        samples.append(flow_samples)\n",
    "        print(\"\")\n",
    "\n",
    "    return flows, losses, samples\n",
    "\n",
    "\n",
    "def do_flow_each_dim(\n",
    "    data,\n",
    "    num_ndes,\n",
    "    n_samples=1000,\n",
    "    max_hidden=128,\n",
    "    max_flows=1,\n",
    "    min_flows=1,\n",
    "    num_epochs=100,\n",
    "    lr=5e-5,\n",
    "    batch_size=1024,\n",
    "):\n",
    "    full_flows, full_losses, full_samples = {}, {}, {}\n",
    "    for i, prop in enumerate(properties):\n",
    "        print(\"Training flow for %s...\" % (prop))\n",
    "\n",
    "        prop_data = data.copy()\n",
    "        prop_data[\"y_train\"] = data[\"y_train\"][:, i].reshape(-1, 1)\n",
    "        prop_data[\"y_test\"] = data[\"y_test\"][:, i].reshape(-1, 1)\n",
    "\n",
    "        flows, losses, samples = do_flow(\n",
    "            prop_data,\n",
    "            num_ndes,\n",
    "            n_samples=n_samples,\n",
    "            max_hidden=max_hidden,\n",
    "            max_flows=max_flows,\n",
    "            min_flows=min_flows,\n",
    "            num_epochs=num_epochs,\n",
    "            lr=lr,\n",
    "            batch_size=batch_size,\n",
    "        )\n",
    "\n",
    "        full_flows[prop] = flows\n",
    "        full_losses[prop] = losses\n",
    "        full_samples[prop] = samples\n",
    "        print(\"\")\n",
    "\n",
    "    return full_flows, full_losses, full_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a8d473",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Files\n",
    "embedding_file = \"/mnt/home/lparker/ceph/good_embeddings/newest_embeddings.h5py\"\n",
    "stein_embedding_file = \"/mnt/home/lparker/ceph/stein_propertyembeddings.h5\"\n",
    "DINO_embedding_file = \"/mnt/home/lparker/ceph/DINO_embeddings.h5\"\n",
    "GalFormer_embedding_file = \"/mnt/home/lparker/ceph/GalFormer_embeddings.h5\"\n",
    "\n",
    "datasets = {\"images\": {}, \"spectra\": {}, \"photometry\": {}}\n",
    "\n",
    "# Load the data\n",
    "print(\"Loading Data...\")\n",
    "datasets[\"images\"][\"clip\"], img_scalers = get_data(embedding_file, source=\"images\")\n",
    "datasets[\"images\"][\"stein\"], _ = get_data(stein_embedding_file, source=\"images\")\n",
    "datasets[\"images\"][\"dino\"], _ = get_data(DINO_embedding_file, source=\"images\")\n",
    "datasets[\"images\"][\"resnet\"], _ = get_supervised(\"resnet\")\n",
    "\n",
    "datasets[\"spectra\"][\"clip\"], spec_scalers = get_data(embedding_file, source=\"spectra\")\n",
    "datasets[\"spectra\"][\"spender\"], _ = get_supervised(\"spender\")\n",
    "datasets[\"spectra\"][\"GalFormer\"], _ = get_data(\n",
    "    GalFormer_embedding_file, source=\"spectra\"\n",
    ")\n",
    "\n",
    "datasets[\"photometry\"][\"mlp\"], _ = get_data(embedding_file, source=\"photometry\")\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66e14a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def expected_coverage_drp(samples, theta, references=\"random\", metric=\"euclidean\"):\n",
    "    \"\"\"\n",
    "    Compute the coverage of a set of samples using DRP regions.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    samples: array-like, shape (n_sims, n_samples, n_dims)\n",
    "        The samples to compute the coverage of.\n",
    "    theta: array-like, shape (n_sims, n_dims)\n",
    "        The true parameter values for each samples.\n",
    "    references: array-like, shape (n_references, n_sims) or 'random'\n",
    "        The reference points to use for the DRP regions. If 'random', then\n",
    "        the reference points are chosen randomly from the parameter space.\n",
    "    metric: string\n",
    "        The metric to use when computing the distance. Can be 'euclidean' or\n",
    "        'manhattan'.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    alpha: array-like,\n",
    "        Credibility values\n",
    "    ecp: array-like,\n",
    "        Expected coverage probability\n",
    "    \"\"\"\n",
    "\n",
    "    samples = samples.permute(1, 0, 2).detach().cpu().numpy()\n",
    "    theta = theta.detach().cpu().numpy()\n",
    "\n",
    "    # Check that shapes are correct\n",
    "    assert len(samples.shape) == 3, \"samples must be a 3D array\"\n",
    "    assert len(theta.shape) == 2, \"theta must be a 2D array\"\n",
    "\n",
    "    num_samples = samples.shape[0]\n",
    "    num_sims = samples.shape[1]\n",
    "    num_dims = samples.shape[2]\n",
    "\n",
    "    assert (\n",
    "        theta.shape[0] == num_sims\n",
    "    ), \"theta must have the same number of rows as samples\"\n",
    "    assert (\n",
    "        theta.shape[1] == num_dims\n",
    "    ), \"theta must have the same number of columns as samples\"\n",
    "\n",
    "    # Reshape theta\n",
    "    theta = theta[np.newaxis, :, :]\n",
    "\n",
    "    # Normalize\n",
    "    low = np.min(theta, axis=1, keepdims=True)\n",
    "    high = np.max(theta, axis=1, keepdims=True)\n",
    "\n",
    "    # Generate reference points\n",
    "    if isinstance(references, str) and references == \"random\":\n",
    "        references = np.random.uniform(low=0, high=1, size=(num_sims, num_dims))\n",
    "        # references = x_test\n",
    "    else:\n",
    "        assert len(references.shape) == 2, \"references must be a 2D array\"\n",
    "        assert (\n",
    "            references.shape[0] == num_sims\n",
    "        ), \"references must have the same number of rows as samples\"\n",
    "        assert (\n",
    "            references.shape[1] == num_dims\n",
    "        ), \"references must have the same number of columns as samples\"\n",
    "\n",
    "    # Compute distances\n",
    "    if metric == \"euclidean\":\n",
    "        samples_distances = np.sqrt(\n",
    "            np.sum((references[np.newaxis] - samples) ** 2, axis=-1)\n",
    "        )\n",
    "        theta_distances = np.sqrt(np.sum((references - theta) ** 2, axis=-1))\n",
    "    elif metric == \"manhattan\":\n",
    "        samples_distances = np.sum(np.abs(references[np.newaxis] - samples), axis=-1)\n",
    "        theta_distances = np.sum(np.abs(references - theta), axis=-1)\n",
    "    else:\n",
    "        raise ValueError(\"metric must be either 'euclidean' or 'manhattan'\")\n",
    "\n",
    "    # Compute coverage\n",
    "    f = np.sum((samples_distances < theta_distances), axis=0) / num_samples\n",
    "\n",
    "    # Compute expected coverage\n",
    "    h, alpha = np.histogram(f, density=True, bins=num_sims // 10)\n",
    "    dx = alpha[1] - alpha[0]\n",
    "    ecp = np.cumsum(h) * dx\n",
    "    return ecp, alpha[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39fc56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_coverage(source, method):\n",
    "    fig, ax = plt.subplots(1, 5, figsize=(20, 4))\n",
    "    samples = torch.cat(torch.load(f\"flows/{source}/new_{method}_samples.pt\"), dim=1)\n",
    "\n",
    "    for i in range(5):\n",
    "        # for j in range(len(samples)):\n",
    "        ecp, alpha = expected_coverage_drp(\n",
    "            samples[:, :, i][:, :, np.newaxis],\n",
    "            datasets[source][method][\"y_test\"][:, i][:, np.newaxis],\n",
    "            references=\"random\",\n",
    "            metric=\"euclidean\",\n",
    "        )\n",
    "        ax[i].plot(alpha, ecp, alpha=1.0, color=\"blue\")\n",
    "        ax[i].set_title(property_titles[i])\n",
    "        ax[i].set_xlabel(\"Credibility\")\n",
    "        if i == 0:\n",
    "            ax[i].set_ylabel(f\"Expected Coverage\")\n",
    "        else:\n",
    "            ax[i].set_yticklabels([])\n",
    "        ax[i].plot([0, 1], [0, 1], \"k--\")\n",
    "\n",
    "    plt.subplots_adjust(wspace=0.1)\n",
    "    plt.savefig(f\"flows/{source}/{method}.png\", dpi=300, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad9382e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for method in datasets[\"images\"].keys():\n",
    "    plot_coverage(\"images\", method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee87f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "for method in datasets[\"spectra\"].keys():\n",
    "    plot_coverage(\"spectra\", method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778aa0a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_coverage(\"photometry\", \"mlp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178d7c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "source = \"images\"\n",
    "method = \"clip\"\n",
    "\n",
    "random_index = np.random.randint(0, 20000)\n",
    "\n",
    "img_samples = (\n",
    "    torch.cat(torch.load(f\"flows/images/clip_samples.pt\"), dim=1).detach().cpu().numpy()\n",
    ")\n",
    "spec_samples = (\n",
    "    torch.cat(torch.load(f\"flows/spectra/clip_samples.pt\"), dim=1)\n",
    "    .detach()\n",
    "    .cpu()\n",
    "    .numpy()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30930003",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_index = np.random.randint(0, 20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aac1a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc7987de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import corner\n",
    "\n",
    "_img_samples = img_samples[random_index]\n",
    "truths = datasets[\"images\"][\"clip\"][\"y_test\"][random_index, :].detach().cpu().numpy()\n",
    "\n",
    "for i, prop in enumerate(properties):\n",
    "    _img_samples[:, i] = (\n",
    "        img_scalers[prop].inverse_transform(_img_samples[:, i].reshape(-1, 1)).squeeze()\n",
    "    )\n",
    "    truths[i] = img_scalers[prop].inverse_transform(truths[i].reshape(-1, 1)).squeeze()\n",
    "\n",
    "figure = corner.corner(\n",
    "    _img_samples,\n",
    "    labels=property_titles,\n",
    "    show_titles=True,\n",
    "    title_kwargs={\"fontsize\": 12},\n",
    "    truths=truths,\n",
    ")\n",
    "plt.savefig(\"flows/images/clip_corner.png\", dpi=300, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a526c8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import corner\n",
    "\n",
    "_spec_samples = spec_samples[random_index]\n",
    "truths = datasets[\"spectra\"][\"clip\"][\"y_test\"][random_index, :].detach().cpu().numpy()\n",
    "\n",
    "for i, prop in enumerate(properties):\n",
    "    _spec_samples[:, i] = (\n",
    "        spec_scalers[prop]\n",
    "        .inverse_transform(_spec_samples[:, i].reshape(-1, 1))\n",
    "        .squeeze()\n",
    "    )\n",
    "    truths[i] = spec_scalers[prop].inverse_transform(truths[i].reshape(-1, 1)).squeeze()\n",
    "\n",
    "figure = corner.corner(\n",
    "    _spec_samples,\n",
    "    labels=property_titles,\n",
    "    show_titles=True,\n",
    "    title_kwargs={\"fontsize\": 12},\n",
    "    truths=truths,\n",
    ")\n",
    "plt.savefig(\"flows/spectra/clip_corner.png\", dpi=300, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33960821",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c1b328",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
